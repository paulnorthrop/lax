[{"path":"https://github.com/paulnorthrop/lax/articles/lax-vignette.html","id":"gev-regression-of-annual-maximum-temperatures","dir":"Articles","previous_headings":"","what":"GEV regression of annual maximum temperatures","title":"An overview of lax","text":"example based analysis presented Section 5.2 Chandler Bate (2007). data, available data frame ow, bivariate time series annual maximum temperatures, recorded degrees Fahrenheit, Oxford Worthing England, period 1901 1980. interest marginal distributions high temperatures Oxford Worthing, might fit GEV regression model parameters may vary Oxford Worthing. However, adjust cluster dependence temperatures recorded year.","code":""},{"path":"https://github.com/paulnorthrop/lax/articles/lax-vignette.html","id":"ismev","dir":"Articles","previous_headings":"","what":"ismev","title":"An overview of lax","text":"gev.fit() function ismev fits GEV regression models. allows covariate effects (location, scale shape) parameters GEV distribution. However, object returned gev.fit() provide information fitted regression model alogLik needs, order calculate loglikelihood contributions individual observations: design matrices missing. Therefore, lax provides function gev_refit, version gev.fit adds information. following code fits GEV regression model location, scale shape parameters GEV distribution vary Oxford Worthing. alogLik used provide adjusted standard errors adjusted loglikelihood. reproduces values rows 1, 3 4 Table 2 Chandler Bate (2007). estimation ‘meat’ sandwich adjustment performed using sandwich package. example, need pass cadjust = FALSE sandwich::meatCL order adjustment used Chandler Bate (2007). Otherwise, meatCL makes finite-cluster bias correction.","code":"library(lax) # Column 4 of ow contains 1 for Oxford and -1 for Worthing large <- gev_refit(ow$temp, ow, mul = 4, sigl = 4, shl = 4, show = FALSE,                    method = \"BFGS\") # Adjust the loglikelihood and standard errors adj_large <- alogLik(large, cluster = ow$year, cadjust = FALSE) # MLEs, SEs and adjusted SEs t(summary(adj_large)) #>             loc locloc  scale scaleloc    shape shapeloc #> MLE     81.1700 2.6690 3.7290   0.5312 -0.19890 -0.08835 #> SE       0.3282 0.3282 0.2292   0.2292  0.04937  0.04937 #> adj. SE  0.4036 0.2128 0.2425   0.1911  0.03944  0.03625"},{"path":"https://github.com/paulnorthrop/lax/articles/lax-vignette.html","id":"confidence-intervals","dir":"Articles","previous_headings":"ismev","what":"Confidence intervals","title":"An overview of lax","text":"confint method calculates approximate (95%) confidence intervals parameters, based adjusted loglikelihood. Chandler Bate (2007) consider three types loglikelihood adjustment: one vertical two horizontal. type adjustment selected argument type. default type = \"vertical\" option perform adjustment.","code":"confint(adj_large) #> Waiting for profiling to be done... #>               2.5 %     97.5 % #> loc      80.3729001 81.9602100 #> locloc    2.2437419  3.0831279 #> scale     3.2991896  4.2598984 #> scaleloc  0.1611912  0.9433844 #> shape    -0.2741177 -0.1157069 #> shapeloc -0.1652089 -0.0200268 confint(adj_large, type = \"none\") #> Waiting for profiling to be done... #>                2.5 %       97.5 % #> loc      80.52440863 81.813160870 #> locloc    2.01969229  3.308352990 #> scale     3.32435238  4.236272757 #> scaleloc  0.09100223  1.020139218 #> shape    -0.28957175 -0.094326264 #> shapeloc -0.18850187  0.008628523"},{"path":"https://github.com/paulnorthrop/lax/articles/lax-vignette.html","id":"confidence-regions","dir":"Articles","previous_headings":"ismev","what":"Confidence regions","title":"An overview of lax","text":"conf_region function chandwich package can used produce confidence regions pairs parameters. , consider ‘central’ (midway Oxford Worthing) scale shape intercept parameters: \\(\\sigma_0\\) \\(\\xi_0\\) Chandler Bate (2007).","code":"library(chandwich) which_pars <- c(\"scale\", \"shape\") gev_none <- conf_region(adj_large, which_pars = which_pars, type = \"none\") #> Waiting for profiling to be done... gev_vertical <- conf_region(adj_large, which_pars = which_pars) #> Waiting for profiling to be done... plot(gev_none, gev_vertical, lwd = 2, xlim = c(3.1, 4.5), ylim = c(-0.35, -0.05),      xlab = expression(sigma[0]), ylab = expression(xi[0]))"},{"path":"https://github.com/paulnorthrop/lax/articles/lax-vignette.html","id":"comparing-nested-models","dir":"Articles","previous_headings":"ismev","what":"Comparing nested models","title":"An overview of lax","text":"alogLik also anova method, can used perform (adjusted) loglikelihood ratio tests nested models. illustrate fit, adjust, smaller model, Oxford Worthing common GEV shape parameter, compare model larger one. see adjustment loglikelihood clustering makes enough difference matter: perform test 5% significance level choose larger model adjust smaller model .","code":"small <- gev_refit(ow$temp, ow, mul = 4, sigl = 4, show = FALSE,                     method = \"BFGS\") adj_small <- alogLik(small, cluster = ow$year, cadjust = FALSE) summary(adj_small) #>              MLE     SE adj. SE #> loc      81.1200 0.3260 0.40640 #> locloc    2.4540 0.3047 0.20370 #> scale     3.7230 0.2232 0.24020 #> scaleloc  0.3537 0.2096 0.16840 #> shape    -0.1845 0.0488 0.04028 anova(adj_large, adj_small) #> Analysis of (Adjusted) Deviance Table #>  #>           Model.Df Df  ALRTS Pr(>ALRTS)   #> adj_large        6                        #> adj_small        5  1 6.3572    0.01169 * #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 anova(adj_large, adj_small, type = \"none\") #> Analysis of (Adjusted) Deviance Table #>  #>           Model.Df Df  ALRTS Pr(>ALRTS)   #> adj_large        6                        #> adj_small        5  1 3.1876     0.0742 . #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"},{"path":"https://github.com/paulnorthrop/lax/articles/lax-vignette.html","id":"texmex","dir":"Articles","previous_headings":"","what":"texmex","title":"An overview of lax","text":"","code":"# This code is not run, to avoid an error from evm(), so there are no results library(texmex, quietly = TRUE) # Note: phi = log(scale) evm_fit <- evm(temp, ow, gev, mu = ~ loc, phi = ~ loc, xi = ~loc) adj_evm_fit <- alogLik(evm_fit, cluster = ow$year) summary(adj_evm_fit)"},{"path":"https://github.com/paulnorthrop/lax/articles/lax-vignette.html","id":"evd","dir":"Articles","previous_headings":"","what":"evd","title":"An overview of lax","text":"fgev() function evd fits GEV regression models, allows covariate effects location parameter.","code":"library(evd, quietly = TRUE) fgev_fit <- fgev(ow$temp, nsloc = ow[, \"loc\"]) adj_fgev_fit <- alogLik(fgev_fit, cluster = ow$year) summary(adj_fgev_fit) #>              MLE      SE adj. SE #> loc      81.1600 0.32980 0.40830 #> loctrend  2.5040 0.31080 0.19910 #> scale     3.7900 0.22810 0.25230 #> shape    -0.2097 0.04765 0.04063"},{"path":"https://github.com/paulnorthrop/lax/articles/lax-vignette.html","id":"extremes","dir":"Articles","previous_headings":"","what":"extRemes","title":"An overview of lax","text":"","code":"library(extRemes, quietly = TRUE) fevd_fit <- fevd(temp, ow, location.fun = ~ ow$loc, scale.fun = ~ ow$loc,                  shape.fun = ~ ow$loc) adj_fevd_fit <- alogLik(fevd_fit, cluster = ow$year) summary(adj_fevd_fit) #>             MLE      SE adj. SE #> mu0    81.17000 0.32820 0.40620 #> mu1     2.66800 0.32820 0.21420 #> sigma0  3.72900 0.22930 0.24410 #> sigma1  0.53090 0.22930 0.19230 #> xi0    -0.19890 0.04938 0.03969 #> xi1    -0.08828 0.04938 0.03648"},{"path":"https://github.com/paulnorthrop/lax/articles/lax-vignette.html","id":"eva","dir":"Articles","previous_headings":"","what":"eva","title":"An overview of lax","text":"","code":"library(eva, quietly = TRUE) gevr_fit <- gevrFit(ow$temp, information = \"observed\",                     locvars = ow, locform = ~ ow$loc,                      scalevars = ow, scaleform = ~ ow$loc,                     shapevars = ow, shapeform = ~ ow$loc) adj_gevr_fit <- alogLik(gevr_fit, cluster = ow$year) summary(adj_gevr_fit) #>                          MLE      SE adj. SE #> Location (Intercept) 81.1700 0.32810 0.40620 #> Location ow$loc       2.6680 0.32810 0.21420 #> Scale (Intercept)     3.7290 0.22920 0.24400 #> Scale ow$loc          0.5307 0.22920 0.19230 #> Shape (Intercept)    -0.1989 0.04936 0.03968 #> Shape ow$loc         -0.0882 0.04936 0.03647"},{"path":"https://github.com/paulnorthrop/lax/articles/lax-vignette.html","id":"evir","dir":"Articles","previous_headings":"","what":"evir","title":"An overview of lax","text":"gev() function evir fits stationary GEV models.","code":"library(evir, quietly = TRUE) gev_fit <- gev(ow$temp) adj_gev_fit <- alogLik(gev_fit) summary(adj_gev_fit) #>           MLE      SE adj. SE #> xi    -0.1801 0.06051  0.0509 #> sigma  4.3980 0.28180  0.2558 #> mu    80.7800 0.39240  0.4128"},{"path":"https://github.com/paulnorthrop/lax/articles/lax-vignette.html","id":"fextremes","dir":"Articles","previous_headings":"","what":"fExtremes","title":"An overview of lax","text":"gevFit() function fExtremes fits stationary GEV models.","code":"library(fExtremes, quietly = TRUE) gevFit_fit <- gevFit(ow$temp) adj_gevFit_fit <- alogLik(gevFit_fit) summary(adj_gevFit_fit) #>          MLE      SE adj. SE #> xi   -0.1802 0.06047 0.05087 #> mu   80.7900 0.39240 0.41290 #> beta  4.3980 0.28170 0.25570"},{"path":"https://github.com/paulnorthrop/lax/articles/lax-vignette.html","id":"mev","dir":"Articles","previous_headings":"","what":"mev","title":"An overview of lax","text":"fit.gev() function mev fits stationary GEV models.","code":"library(mev, quietly = TRUE) gfit <- fit.gev(ow$temp) adj_gfit <- alogLik(gfit) summary(adj_gfit) #>           MLE     SE adj. SE #> loc   80.7800 0.3924 0.41290 #> scale  4.3980 0.2818 0.25580 #> shape -0.1801 0.0605 0.05089"},{"path":"https://github.com/paulnorthrop/lax/articles/lax-vignette.html","id":"pot","dir":"Articles","previous_headings":"","what":"POT","title":"An overview of lax","text":"Among things, fitgpd() function POT package can fit GP distribution threshold excesses using maximum likelihood estimation. illustrate alogLik using example fitgpd documentation. cluster dependence . However, may interest using sandwich estimator covariance concerned model misspecification. case, simulate correct model, expect adjustment make little difference, proves.","code":"library(POT, quietly = TRUE) set.seed(24082019) x <- POT::rgpd(200, 1, 2, 0.25) fit <- fitgpd(x, 1, \"mle\") adj_fit <- alogLik(fit) summary(adj_fit) #>          MLE      SE adj. SE #> scale 1.8670 0.20930 0.19260 #> shape 0.2573 0.08887 0.07121"},{"path":[]},{"path":"https://github.com/paulnorthrop/lax/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Paul J. Northrop. Author, maintainer, copyright holder. Camellia Yin. Author, copyright holder.","code":""},{"path":"https://github.com/paulnorthrop/lax/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Northrop PJ, Yin C (2025). lax: Loglikelihood Adjustment Extreme Value Models. R package version 1.2.4, https://paulnorthrop.github.io/lax/.","code":"@Manual{,   title = {lax: Loglikelihood Adjustment for Extreme Value Models},   author = {Paul J. Northrop and Camellia Yin},   year = {2025},   note = {R package version 1.2.4},   url = {https://paulnorthrop.github.io/lax/}, }"},{"path":[]},{"path":[]},{"path":"https://github.com/paulnorthrop/lax/index.html","id":"what-does-lax-do","dir":"","previous_headings":"Loglikelihood Adjustment for Extreme Value Models","what":"What does lax do?","title":"Loglikelihood Adjustment for Extreme Value Models","text":"CRAN Task View Extreme Value Analysis provides information R packages perform various extreme value analyses. lax package supplements univariate extreme value modelling, including regression modelling, provided 9 packages, namely eva, evd, evir, extRemes, fExtremes, ismev, mev, POT texmex. lax works object-oriented way, operating R objects returned functions packages summarise fit extreme value model. uses chandwich package provide robust sandwich estimation parameter covariance matrix loglikelihood adjustment models fitted maximum likelihood estimation. performed alogLik S3 method, illustrated following example.","code":""},{"path":"https://github.com/paulnorthrop/lax/index.html","id":"an-example","dir":"","previous_headings":"Loglikelihood Adjustment for Extreme Value Models","what":"An example","title":"Loglikelihood Adjustment for Extreme Value Models","text":"example based analysis presented Section 5.2 Chandler Bate (2007). data, available data frame ow, bivariate time series annual maximum temperatures, recorded degrees Fahrenheit, Oxford Worthing England, period 1901 1980. interest marginal distributions high temperatures Oxford Worthing, might fit GEV regression model parameters may vary Oxford Worthing. However, adjust cluster dependence temperatures recorded year. following code fits model using fevd function extRemes package uses alogLik perform adjusted inferences. object returned aloglik function evaluate adjusted loglikelihood, anova, coef, confint, logLik, nobs, plot, print, summary vcov methods.","code":"library(lax) library(extRemes, quietly = TRUE) #>  #> Attaching package: 'extRemes' #> The following objects are masked from 'package:stats': #>  #>     qqnorm, qqplot # Fit a GEV model with separate location, scale and shape for Oxford and Worthing # Note: phi = log(scale) evm_fit <- fevd(temp, ow, location.fun = ~ loc, scale.fun = ~ loc,                  shape.fun = ~ loc) # Adjust the loglikelihood and standard errors adj_evm_fit <- alogLik(evm_fit, cluster = ow$year, cadjust = FALSE) # MLEs, SEs and adjusted SEs summary(adj_evm_fit) #>             MLE      SE adj. SE #> mu0    81.17000 0.32820 0.40360 #> mu1     2.66800 0.32820 0.21280 #> sigma0  3.72900 0.22930 0.24260 #> sigma1  0.53090 0.22930 0.19110 #> xi0    -0.19890 0.04938 0.03944 #> xi1    -0.08828 0.04938 0.03625"},{"path":"https://github.com/paulnorthrop/lax/index.html","id":"installation","dir":"","previous_headings":"Loglikelihood Adjustment for Extreme Value Models","what":"Installation","title":"Loglikelihood Adjustment for Extreme Value Models","text":"get current released version CRAN:","code":"install.packages(\"lax\")"},{"path":"https://github.com/paulnorthrop/lax/index.html","id":"vignette","dir":"","previous_headings":"Loglikelihood Adjustment for Extreme Value Models","what":"Vignette","title":"Loglikelihood Adjustment for Extreme Value Models","text":"See vignette(\"lax-vignette\", package = \"lax\") overview package.","code":""},{"path":"https://github.com/paulnorthrop/lax/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"GNU General Public License","title":"GNU General Public License","text":"Version 3, 29 June 2007Copyright © 2007 Free Software Foundation, Inc. <http://fsf.org/> Everyone permitted copy distribute verbatim copies license document, changing allowed.","code":""},{"path":"https://github.com/paulnorthrop/lax/LICENSE.html","id":"preamble","dir":"","previous_headings":"","what":"Preamble","title":"GNU General Public License","text":"GNU General Public License free, copyleft license software kinds works. licenses software practical works designed take away freedom share change works. contrast, GNU General Public License intended guarantee freedom share change versions program–make sure remains free software users. , Free Software Foundation, use GNU General Public License software; applies also work released way authors. can apply programs, . speak free software, referring freedom, price. General Public Licenses designed make sure freedom distribute copies free software (charge wish), receive source code can get want , can change software use pieces new free programs, know can things. protect rights, need prevent others denying rights asking surrender rights. Therefore, certain responsibilities distribute copies software, modify : responsibilities respect freedom others. example, distribute copies program, whether gratis fee, must pass recipients freedoms received. must make sure , , receive can get source code. must show terms know rights. Developers use GNU GPL protect rights two steps: (1) assert copyright software, (2) offer License giving legal permission copy, distribute /modify . developers’ authors’ protection, GPL clearly explains warranty free software. users’ authors’ sake, GPL requires modified versions marked changed, problems attributed erroneously authors previous versions. devices designed deny users access install run modified versions software inside , although manufacturer can . fundamentally incompatible aim protecting users’ freedom change software. systematic pattern abuse occurs area products individuals use, precisely unacceptable. Therefore, designed version GPL prohibit practice products. problems arise substantially domains, stand ready extend provision domains future versions GPL, needed protect freedom users. Finally, every program threatened constantly software patents. States allow patents restrict development use software general-purpose computers, , wish avoid special danger patents applied free program make effectively proprietary. prevent , GPL assures patents used render program non-free. precise terms conditions copying, distribution modification follow.","code":""},{"path":[]},{"path":"https://github.com/paulnorthrop/lax/LICENSE.html","id":"id_0-definitions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"0. Definitions","title":"GNU General Public License","text":"“License” refers version 3 GNU General Public License. “Copyright” also means copyright-like laws apply kinds works, semiconductor masks. “Program” refers copyrightable work licensed License. licensee addressed “”. “Licensees” “recipients” may individuals organizations. “modify” work means copy adapt part work fashion requiring copyright permission, making exact copy. resulting work called “modified version” earlier work work “based ” earlier work. “covered work” means either unmodified Program work based Program. “propagate” work means anything , without permission, make directly secondarily liable infringement applicable copyright law, except executing computer modifying private copy. Propagation includes copying, distribution (without modification), making available public, countries activities well. “convey” work means kind propagation enables parties make receive copies. Mere interaction user computer network, transfer copy, conveying. interactive user interface displays “Appropriate Legal Notices” extent includes convenient prominently visible feature (1) displays appropriate copyright notice, (2) tells user warranty work (except extent warranties provided), licensees may convey work License, view copy License. interface presents list user commands options, menu, prominent item list meets criterion.","code":""},{"path":"https://github.com/paulnorthrop/lax/LICENSE.html","id":"id_1-source-code","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"1. Source Code","title":"GNU General Public License","text":"“source code” work means preferred form work making modifications . “Object code” means non-source form work. “Standard Interface” means interface either official standard defined recognized standards body, , case interfaces specified particular programming language, one widely used among developers working language. “System Libraries” executable work include anything, work whole, () included normal form packaging Major Component, part Major Component, (b) serves enable use work Major Component, implement Standard Interface implementation available public source code form. “Major Component”, context, means major essential component (kernel, window system, ) specific operating system () executable work runs, compiler used produce work, object code interpreter used run . “Corresponding Source” work object code form means source code needed generate, install, (executable work) run object code modify work, including scripts control activities. However, include work’s System Libraries, general-purpose tools generally available free programs used unmodified performing activities part work. example, Corresponding Source includes interface definition files associated source files work, source code shared libraries dynamically linked subprograms work specifically designed require, intimate data communication control flow subprograms parts work. Corresponding Source need include anything users can regenerate automatically parts Corresponding Source. Corresponding Source work source code form work.","code":""},{"path":"https://github.com/paulnorthrop/lax/LICENSE.html","id":"id_2-basic-permissions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"2. Basic Permissions","title":"GNU General Public License","text":"rights granted License granted term copyright Program, irrevocable provided stated conditions met. License explicitly affirms unlimited permission run unmodified Program. output running covered work covered License output, given content, constitutes covered work. License acknowledges rights fair use equivalent, provided copyright law. may make, run propagate covered works convey, without conditions long license otherwise remains force. may convey covered works others sole purpose make modifications exclusively , provide facilities running works, provided comply terms License conveying material control copyright. thus making running covered works must exclusively behalf, direction control, terms prohibit making copies copyrighted material outside relationship . Conveying circumstances permitted solely conditions stated . Sublicensing allowed; section 10 makes unnecessary.","code":""},{"path":"https://github.com/paulnorthrop/lax/LICENSE.html","id":"id_3-protecting-users-legal-rights-from-anti-circumvention-law","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"3. Protecting Users’ Legal Rights From Anti-Circumvention Law","title":"GNU General Public License","text":"covered work shall deemed part effective technological measure applicable law fulfilling obligations article 11 WIPO copyright treaty adopted 20 December 1996, similar laws prohibiting restricting circumvention measures. convey covered work, waive legal power forbid circumvention technological measures extent circumvention effected exercising rights License respect covered work, disclaim intention limit operation modification work means enforcing, work’s users, third parties’ legal rights forbid circumvention technological measures.","code":""},{"path":"https://github.com/paulnorthrop/lax/LICENSE.html","id":"id_4-conveying-verbatim-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"4. Conveying Verbatim Copies","title":"GNU General Public License","text":"may convey verbatim copies Program’s source code receive , medium, provided conspicuously appropriately publish copy appropriate copyright notice; keep intact notices stating License non-permissive terms added accord section 7 apply code; keep intact notices absence warranty; give recipients copy License along Program. may charge price price copy convey, may offer support warranty protection fee.","code":""},{"path":"https://github.com/paulnorthrop/lax/LICENSE.html","id":"id_5-conveying-modified-source-versions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"5. Conveying Modified Source Versions","title":"GNU General Public License","text":"may convey work based Program, modifications produce Program, form source code terms section 4, provided also meet conditions: ) work must carry prominent notices stating modified , giving relevant date. b) work must carry prominent notices stating released License conditions added section 7. requirement modifies requirement section 4 “keep intact notices”. c) must license entire work, whole, License anyone comes possession copy. License therefore apply, along applicable section 7 additional terms, whole work, parts, regardless packaged. License gives permission license work way, invalidate permission separately received . d) work interactive user interfaces, must display Appropriate Legal Notices; however, Program interactive interfaces display Appropriate Legal Notices, work need make . compilation covered work separate independent works, nature extensions covered work, combined form larger program, volume storage distribution medium, called “aggregate” compilation resulting copyright used limit access legal rights compilation’s users beyond individual works permit. Inclusion covered work aggregate cause License apply parts aggregate.","code":""},{"path":"https://github.com/paulnorthrop/lax/LICENSE.html","id":"id_6-conveying-non-source-forms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"6. Conveying Non-Source Forms","title":"GNU General Public License","text":"may convey covered work object code form terms sections 4 5, provided also convey machine-readable Corresponding Source terms License, one ways: ) Convey object code , embodied , physical product (including physical distribution medium), accompanied Corresponding Source fixed durable physical medium customarily used software interchange. b) Convey object code , embodied , physical product (including physical distribution medium), accompanied written offer, valid least three years valid long offer spare parts customer support product model, give anyone possesses object code either (1) copy Corresponding Source software product covered License, durable physical medium customarily used software interchange, price reasonable cost physically performing conveying source, (2) access copy Corresponding Source network server charge. c) Convey individual copies object code copy written offer provide Corresponding Source. alternative allowed occasionally noncommercially, received object code offer, accord subsection 6b. d) Convey object code offering access designated place (gratis charge), offer equivalent access Corresponding Source way place charge. need require recipients copy Corresponding Source along object code. place copy object code network server, Corresponding Source may different server (operated third party) supports equivalent copying facilities, provided maintain clear directions next object code saying find Corresponding Source. Regardless server hosts Corresponding Source, remain obligated ensure available long needed satisfy requirements. e) Convey object code using peer--peer transmission, provided inform peers object code Corresponding Source work offered general public charge subsection 6d. separable portion object code, whose source code excluded Corresponding Source System Library, need included conveying object code work. “User Product” either (1) “consumer product”, means tangible personal property normally used personal, family, household purposes, (2) anything designed sold incorporation dwelling. determining whether product consumer product, doubtful cases shall resolved favor coverage. particular product received particular user, “normally used” refers typical common use class product, regardless status particular user way particular user actually uses, expects expected use, product. product consumer product regardless whether product substantial commercial, industrial non-consumer uses, unless uses represent significant mode use product. “Installation Information” User Product means methods, procedures, authorization keys, information required install execute modified versions covered work User Product modified version Corresponding Source. information must suffice ensure continued functioning modified object code case prevented interfered solely modification made. convey object code work section , , specifically use , User Product, conveying occurs part transaction right possession use User Product transferred recipient perpetuity fixed term (regardless transaction characterized), Corresponding Source conveyed section must accompanied Installation Information. requirement apply neither third party retains ability install modified object code User Product (example, work installed ROM). requirement provide Installation Information include requirement continue provide support service, warranty, updates work modified installed recipient, User Product modified installed. Access network may denied modification materially adversely affects operation network violates rules protocols communication across network. Corresponding Source conveyed, Installation Information provided, accord section must format publicly documented (implementation available public source code form), must require special password key unpacking, reading copying.","code":""},{"path":"https://github.com/paulnorthrop/lax/LICENSE.html","id":"id_7-additional-terms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"7. Additional Terms","title":"GNU General Public License","text":"“Additional permissions” terms supplement terms License making exceptions one conditions. Additional permissions applicable entire Program shall treated though included License, extent valid applicable law. additional permissions apply part Program, part may used separately permissions, entire Program remains governed License without regard additional permissions. convey copy covered work, may option remove additional permissions copy, part . (Additional permissions may written require removal certain cases modify work.) may place additional permissions material, added covered work, can give appropriate copyright permission. Notwithstanding provision License, material add covered work, may (authorized copyright holders material) supplement terms License terms: ) Disclaiming warranty limiting liability differently terms sections 15 16 License; b) Requiring preservation specified reasonable legal notices author attributions material Appropriate Legal Notices displayed works containing ; c) Prohibiting misrepresentation origin material, requiring modified versions material marked reasonable ways different original version; d) Limiting use publicity purposes names licensors authors material; e) Declining grant rights trademark law use trade names, trademarks, service marks; f) Requiring indemnification licensors authors material anyone conveys material (modified versions ) contractual assumptions liability recipient, liability contractual assumptions directly impose licensors authors. non-permissive additional terms considered “restrictions” within meaning section 10. Program received , part , contains notice stating governed License along term restriction, may remove term. license document contains restriction permits relicensing conveying License, may add covered work material governed terms license document, provided restriction survive relicensing conveying. add terms covered work accord section, must place, relevant source files, statement additional terms apply files, notice indicating find applicable terms. Additional terms, permissive non-permissive, may stated form separately written license, stated exceptions; requirements apply either way.","code":""},{"path":"https://github.com/paulnorthrop/lax/LICENSE.html","id":"id_8-termination","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"8. Termination","title":"GNU General Public License","text":"may propagate modify covered work except expressly provided License. attempt otherwise propagate modify void, automatically terminate rights License (including patent licenses granted third paragraph section 11). However, cease violation License, license particular copyright holder reinstated () provisionally, unless copyright holder explicitly finally terminates license, (b) permanently, copyright holder fails notify violation reasonable means prior 60 days cessation. Moreover, license particular copyright holder reinstated permanently copyright holder notifies violation reasonable means, first time received notice violation License (work) copyright holder, cure violation prior 30 days receipt notice. Termination rights section terminate licenses parties received copies rights License. rights terminated permanently reinstated, qualify receive new licenses material section 10.","code":""},{"path":"https://github.com/paulnorthrop/lax/LICENSE.html","id":"id_9-acceptance-not-required-for-having-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"9. Acceptance Not Required for Having Copies","title":"GNU General Public License","text":"required accept License order receive run copy Program. Ancillary propagation covered work occurring solely consequence using peer--peer transmission receive copy likewise require acceptance. However, nothing License grants permission propagate modify covered work. actions infringe copyright accept License. Therefore, modifying propagating covered work, indicate acceptance License .","code":""},{"path":"https://github.com/paulnorthrop/lax/LICENSE.html","id":"id_10-automatic-licensing-of-downstream-recipients","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"10. Automatic Licensing of Downstream Recipients","title":"GNU General Public License","text":"time convey covered work, recipient automatically receives license original licensors, run, modify propagate work, subject License. responsible enforcing compliance third parties License. “entity transaction” transaction transferring control organization, substantially assets one, subdividing organization, merging organizations. propagation covered work results entity transaction, party transaction receives copy work also receives whatever licenses work party’s predecessor interest give previous paragraph, plus right possession Corresponding Source work predecessor interest, predecessor can get reasonable efforts. may impose restrictions exercise rights granted affirmed License. example, may impose license fee, royalty, charge exercise rights granted License, may initiate litigation (including cross-claim counterclaim lawsuit) alleging patent claim infringed making, using, selling, offering sale, importing Program portion .","code":""},{"path":"https://github.com/paulnorthrop/lax/LICENSE.html","id":"id_11-patents","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"11. Patents","title":"GNU General Public License","text":"“contributor” copyright holder authorizes use License Program work Program based. work thus licensed called contributor’s “contributor version”. contributor’s “essential patent claims” patent claims owned controlled contributor, whether already acquired hereafter acquired, infringed manner, permitted License, making, using, selling contributor version, include claims infringed consequence modification contributor version. purposes definition, “control” includes right grant patent sublicenses manner consistent requirements License. contributor grants non-exclusive, worldwide, royalty-free patent license contributor’s essential patent claims, make, use, sell, offer sale, import otherwise run, modify propagate contents contributor version. following three paragraphs, “patent license” express agreement commitment, however denominated, enforce patent (express permission practice patent covenant sue patent infringement). “grant” patent license party means make agreement commitment enforce patent party. convey covered work, knowingly relying patent license, Corresponding Source work available anyone copy, free charge terms License, publicly available network server readily accessible means, must either (1) cause Corresponding Source available, (2) arrange deprive benefit patent license particular work, (3) arrange, manner consistent requirements License, extend patent license downstream recipients. “Knowingly relying” means actual knowledge , patent license, conveying covered work country, recipient’s use covered work country, infringe one identifiable patents country reason believe valid. , pursuant connection single transaction arrangement, convey, propagate procuring conveyance , covered work, grant patent license parties receiving covered work authorizing use, propagate, modify convey specific copy covered work, patent license grant automatically extended recipients covered work works based . patent license “discriminatory” include within scope coverage, prohibits exercise , conditioned non-exercise one rights specifically granted License. may convey covered work party arrangement third party business distributing software, make payment third party based extent activity conveying work, third party grants, parties receive covered work , discriminatory patent license () connection copies covered work conveyed (copies made copies), (b) primarily connection specific products compilations contain covered work, unless entered arrangement, patent license granted, prior 28 March 2007. Nothing License shall construed excluding limiting implied license defenses infringement may otherwise available applicable patent law.","code":""},{"path":"https://github.com/paulnorthrop/lax/LICENSE.html","id":"id_12-no-surrender-of-others-freedom","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"12. No Surrender of Others’ Freedom","title":"GNU General Public License","text":"conditions imposed (whether court order, agreement otherwise) contradict conditions License, excuse conditions License. convey covered work satisfy simultaneously obligations License pertinent obligations, consequence may convey . example, agree terms obligate collect royalty conveying convey Program, way satisfy terms License refrain entirely conveying Program.","code":""},{"path":"https://github.com/paulnorthrop/lax/LICENSE.html","id":"id_13-use-with-the-gnu-affero-general-public-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"13. Use with the GNU Affero General Public License","title":"GNU General Public License","text":"Notwithstanding provision License, permission link combine covered work work licensed version 3 GNU Affero General Public License single combined work, convey resulting work. terms License continue apply part covered work, special requirements GNU Affero General Public License, section 13, concerning interaction network apply combination .","code":""},{"path":"https://github.com/paulnorthrop/lax/LICENSE.html","id":"id_14-revised-versions-of-this-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"14. Revised Versions of this License","title":"GNU General Public License","text":"Free Software Foundation may publish revised /new versions GNU General Public License time time. new versions similar spirit present version, may differ detail address new problems concerns. version given distinguishing version number. Program specifies certain numbered version GNU General Public License “later version” applies , option following terms conditions either numbered version later version published Free Software Foundation. Program specify version number GNU General Public License, may choose version ever published Free Software Foundation. Program specifies proxy can decide future versions GNU General Public License can used, proxy’s public statement acceptance version permanently authorizes choose version Program. Later license versions may give additional different permissions. However, additional obligations imposed author copyright holder result choosing follow later version.","code":""},{"path":"https://github.com/paulnorthrop/lax/LICENSE.html","id":"id_15-disclaimer-of-warranty","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"15. Disclaimer of Warranty","title":"GNU General Public License","text":"WARRANTY PROGRAM, EXTENT PERMITTED APPLICABLE LAW. EXCEPT OTHERWISE STATED WRITING COPYRIGHT HOLDERS /PARTIES PROVIDE PROGRAM “” WITHOUT WARRANTY KIND, EITHER EXPRESSED IMPLIED, INCLUDING, LIMITED , IMPLIED WARRANTIES MERCHANTABILITY FITNESS PARTICULAR PURPOSE. ENTIRE RISK QUALITY PERFORMANCE PROGRAM . PROGRAM PROVE DEFECTIVE, ASSUME COST NECESSARY SERVICING, REPAIR CORRECTION.","code":""},{"path":"https://github.com/paulnorthrop/lax/LICENSE.html","id":"id_16-limitation-of-liability","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"16. Limitation of Liability","title":"GNU General Public License","text":"EVENT UNLESS REQUIRED APPLICABLE LAW AGREED WRITING COPYRIGHT HOLDER, PARTY MODIFIES /CONVEYS PROGRAM PERMITTED , LIABLE DAMAGES, INCLUDING GENERAL, SPECIAL, INCIDENTAL CONSEQUENTIAL DAMAGES ARISING USE INABILITY USE PROGRAM (INCLUDING LIMITED LOSS DATA DATA RENDERED INACCURATE LOSSES SUSTAINED THIRD PARTIES FAILURE PROGRAM OPERATE PROGRAMS), EVEN HOLDER PARTY ADVISED POSSIBILITY DAMAGES.","code":""},{"path":"https://github.com/paulnorthrop/lax/LICENSE.html","id":"id_17-interpretation-of-sections-15-and-16","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"17. Interpretation of Sections 15 and 16","title":"GNU General Public License","text":"disclaimer warranty limitation liability provided given local legal effect according terms, reviewing courts shall apply local law closely approximates absolute waiver civil liability connection Program, unless warranty assumption liability accompanies copy Program return fee. END TERMS CONDITIONS","code":""},{"path":"https://github.com/paulnorthrop/lax/LICENSE.html","id":"how-to-apply-these-terms-to-your-new-programs","dir":"","previous_headings":"","what":"How to Apply These Terms to Your New Programs","title":"GNU General Public License","text":"develop new program, want greatest possible use public, best way achieve make free software everyone can redistribute change terms. , attach following notices program. safest attach start source file effectively state exclusion warranty; file least “copyright” line pointer full notice found. Also add information contact electronic paper mail. program terminal interaction, make output short notice like starts interactive mode: hypothetical commands show w show c show appropriate parts General Public License. course, program’s commands might different; GUI interface, use “box”. also get employer (work programmer) school, , sign “copyright disclaimer” program, necessary. information , apply follow GNU GPL, see <http://www.gnu.org/licenses/>. GNU General Public License permit incorporating program proprietary programs. program subroutine library, may consider useful permit linking proprietary applications library. want , use GNU Lesser General Public License instead License. first, please read <http://www.gnu.org/philosophy/--lgpl.html>.","code":"<one line to give the program's name and a brief idea of what it does.> Copyright (C) <year>  <name of author>  This program is free software: you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version.  This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for more details.  You should have received a copy of the GNU General Public License along with this program.  If not, see <http://www.gnu.org/licenses/>. <program>  Copyright (C) <year>  <name of author> This program comes with ABSOLUTELY NO WARRANTY; for details type 'show w'. This is free software, and you are welcome to redistribute it under certain conditions; type 'show c' for details."},{"path":"https://github.com/paulnorthrop/lax/reference/alogLik.html","id":null,"dir":"Reference","previous_headings":"","what":"Loglikelihood adjustment for model fits. — alogLik","title":"Loglikelihood adjustment for model fits. — alogLik","text":"function generic.  performs adjustment loglikelihood associated fitted model objects, following Chandler Bate (2007). Certain classes extreme value model objects supported automatically. details see alogLik help pages packages: evd, evir, extRemes, fExtremes, ismev, mev, POT, texmex. User-supplied objects can also supported: requirements objects explained Details.","code":""},{"path":"https://github.com/paulnorthrop/lax/reference/alogLik.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Loglikelihood adjustment for model fits. — alogLik","text":"","code":"alogLik(   x,   cluster = NULL,   use_vcov = TRUE,   binom = FALSE,   k,   inc_cens = TRUE,   ... )"},{"path":"https://github.com/paulnorthrop/lax/reference/alogLik.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Loglikelihood adjustment for model fits. — alogLik","text":"x fitted model object certain associated S3 methods. See Details. cluster vector factor indicating cluster   respective log-likelihood contributions loglik originate.   length cluster must consistent estfun   method used estimation 'meat' V sandwich   estimator covariance matrix parameters passed   adjust_loglik.  cases, cluster   must length equal number observations data.    exception GP () model (binom = FALSE),   cluster may either contain value observation raw   data, threshold exceedance data. cluster supplied (NULL)   assumed observation forms cluster.   See Details details. use_vcov logical scalar.  use vcov S3 method x (exists) estimate Hessian independence loglikelihood passed argument H adjust_loglik? Otherwise, H estimated inside adjust_loglik using optimHess. binom logical scalar.  option relevant GP models available stationary (covariates) case. binom = FALSE loglikelihood adjustment performed using GP model. binom = TRUE loglikelihood adjustment also performed inferences probability threshold exceedance, using Bernoulli model instances threshold exceedance. k non-negative integer scalar.  option relevant GP models available stationary (covariates) case.  k supplied passed run parameter \\(K\\) kgaps making inferences extremal index \\(\\theta\\) using \\(K\\)-gaps model Suveges Davison (2010). inc_cens logical scalar.  argument relevant k supplied.  Passed kgaps indicate whether include censored inter-exceedance times, relating first last observations. ... arguments passed functions sandwich package meat (cluster = NULL), meatCL (cluster NULL).","code":""},{"path":"https://github.com/paulnorthrop/lax/reference/alogLik.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Loglikelihood adjustment for model fits. — alogLik","text":"object inheriting class \"chandwich\".  See   adjust_loglik. original fitted model object available attribute named   \"original_fit\", accessible using attr(name, \"original_fit\"),   name name object object returned   alogLik assigned. binom = TRUE returned object extra attribute   named pu_aloglik contains object inheriting class   \"chandwich\" relating specifically inferences   probability threshold exceedance. Also, 4th component class   returned object becomes \"bin-gpd\". k supplied returned object extra attribute   named theta contains object inheriting class   c(\"kgaps\", \"exdex\") relating specifically inferences   extremal index \\(\\theta\\).  See Value section   kgaps. x one supported models class returned   object vector length 5. first 3 components   c(\"lax\", \"chandwich\", \"name_of_package\"),   \"name_of_package\" name package input   object x originated.  remaining 2 components depend   model fitted.  See documentation relevant package   details:   evd,   evir,   extRemes,   fExtremes,   ismev,   mev,   POT,   texmex. Otherwise, class returned object   c(\"lax\", \"chandwich\", class(x)). Objects returned `aloglik` `anova`, `coef`, `confint`, `logLik`,   `nobs`, `plot`, `print`, `summary` `vcov` methods.","code":""},{"path":"https://github.com/paulnorthrop/lax/reference/alogLik.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Loglikelihood adjustment for model fits. — alogLik","text":"Object x must following S3   methods: logLikVec: returns vector contributions       independence loglikelihood individual observations; coef: returns vector model coefficients, see       coef; nobs: returns number (non-missing) observations       used model fit, see nobs; may following S3 methods vcov: returns estimated variance-covariance matrix       (main) parameters fitted model, see       vcov; estfun: returns \\(n\\) \\(k\\) matrix,       column gives derivative loglikelihood \\(n\\)       observation respect \\(k\\) parameters model, see       estfun. Loglikelihood adjustment performed using   adjust_loglik function   chandwich package.   relevant arguments adjust_loglik, namely   loglik, mle, H V, created based class   object x. vcov method available, use_vcov = FALSE,   variance-covariance matrix MLE (H   calculated) estimated inside adjust_loglik   using optimHess. sandwich package used estimate variance matrix   V score vector: meat used   cluster = NULL; meatCL used   cluster NULL.   cluster NULL arguments   meatCL present ... ignored.   Similarly, cluster NULL arguments   meat present ... ignored.   meat meatCL   require estfun method available, ,   current context, provides matrix score contributions.   bespoke estfun method provided constructed   estimating score contributions using jacobian.","code":""},{"path":"https://github.com/paulnorthrop/lax/reference/alogLik.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Loglikelihood adjustment for model fits. — alogLik","text":"See (package-specific) examples evd,   evir, extRemes,fExtremes,   ismev, mev, POT   texmex.","code":""},{"path":"https://github.com/paulnorthrop/lax/reference/alogLik.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Loglikelihood adjustment for model fits. — alogLik","text":"Chandler, R. E. Bate, S. (2007). Inference clustered   data using independence loglikelihood. Biometrika,   94(1), 167-183. doi:10.1093/biomet/asm015 Suveges, M. Davison, . C. (2010) Model   misspecification peaks threshold analysis, Annals   Applied Statistics, 4(1), 203-221.   doi:10.1214/09-AOAS292 Zeileis (2006) Object-Oriented Computation Sandwich   Estimators.  Journal Statistical Software, 16, 1-16.   doi:10.18637/jss.v016.i09","code":""},{"path":[]},{"path":"https://github.com/paulnorthrop/lax/reference/anova.lax.html","id":null,"dir":"Reference","previous_headings":"","what":"Comparison of nested models — anova.lax","title":"Comparison of nested models — anova.lax","text":"anova method objects class \"lax\". Compares two nested models using adjusted likelihood ratio test statistic (ALRTS) described Section 3.5 Chandler Bate (2007). nesting must result simple constraint subset parameters larger model held fixed.","code":""},{"path":"https://github.com/paulnorthrop/lax/reference/anova.lax.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Comparison of nested models — anova.lax","text":"","code":"# S3 method for class 'lax' anova(object, object2, ...)"},{"path":"https://github.com/paulnorthrop/lax/reference/anova.lax.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Comparison of nested models — anova.lax","text":"object object class \"lax\", inheriting class \"chandwich\", returned alogLik. object2 object class \"lax\", inheriting class \"chandwich\", returned alogLik. ... objects class \"lax\" /arguments passed anova.chandwich, compare_models, particular type, chooses type adjustment.","code":""},{"path":"https://github.com/paulnorthrop/lax/reference/anova.lax.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Comparison of nested models — anova.lax","text":"object class \"anova\" inheriting class  \"data.frame\", four columns: Model.Df number parameters model Df decrease number parameter compared model       previous row ALRTS adjusted likelihood ratio test statistic Pr(>ALRTS) p-value associated test       model valid simplification model previous row. row names names model objects.","code":""},{"path":"https://github.com/paulnorthrop/lax/reference/anova.lax.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Comparison of nested models — anova.lax","text":"objects class \"lax\" need provided nested   order: ordered inside anova.lax based   values attr(., \"p_current\").","code":""},{"path":"https://github.com/paulnorthrop/lax/reference/anova.lax.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Comparison of nested models — anova.lax","text":"Chandler, R. E. Bate, S. (2007). Inference clustered   data using independence loglikelihood. Biometrika,   94(1), 167-183. doi:10.1093/biomet/asm015","code":""},{"path":[]},{"path":"https://github.com/paulnorthrop/lax/reference/anova.lax.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Comparison of nested models — anova.lax","text":"","code":"got_evd <- requireNamespace(\"evd\", quietly = TRUE) if (got_evd) {   library(evd)   small <- fgev(ow$temp, nsloc = ow[, \"loc\"])   adj_small <- alogLik(small, cluster = ow$year)   tiny <- fgev(ow$temp)   adj_tiny <- alogLik(tiny, cluster = ow$year)   anova(adj_small, adj_tiny)    set.seed(4082019)   uvdata <- evd::rgev(100, loc = 0.13, scale = 1.1, shape = 0.2)   M0 <- fgev(uvdata)   M1 <- fgev(uvdata, nsloc = (-49:50)/100)   adj0 <- alogLik(M0)   adj1 <- alogLik(M1)   anova(adj1, adj0) } #> Analysis of (Adjusted) Deviance Table #>  #>      Model.Df Df ALRTS Pr(>ALRTS) #> adj1        4                     #> adj0        3  1 1.421     0.2332  got_extRemes <- requireNamespace(\"extRemes\", quietly = TRUE) if (got_extRemes) {   library(extRemes)   large <- fevd(temp, ow, location.fun = ~ loc, scale.fun = ~ loc,                 shape.fun = ~ loc)   medium <- fevd(temp, ow, location.fun = ~ loc, scale.fun = ~ loc)   small <- fevd(temp, ow, location.fun = ~ loc)   tiny <- fevd(temp, ow)   adj_large <- alogLik(large, cluster = ow$year)   adj_medium <- alogLik(medium, cluster = ow$year)   adj_small <- alogLik(small, cluster = ow$year)   adj_tiny <- alogLik(tiny, cluster = ow$year)   anova(adj_large, adj_medium, adj_small, adj_tiny) } #> Loading required package: Lmoments #> Loading required package: distillery #>  #> Attaching package: 'extRemes' #> The following object is masked from 'package:evd': #>  #>     mrlplot #> The following objects are masked from 'package:stats': #>  #>     qqnorm, qqplot #> Analysis of (Adjusted) Deviance Table #>  #>            Model.Df Df  ALRTS Pr(>ALRTS)     #> adj_large         6                          #> adj_medium        5  1  6.276    0.01224 *   #> adj_small         4  1  4.198    0.04048 *   #> adj_tiny          3  1 80.697    < 2e-16 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"},{"path":"https://github.com/paulnorthrop/lax/reference/bernoulli.html","id":null,"dir":"Reference","previous_headings":"","what":"Inference for the Bernoulli distribution — bernoulli","title":"Inference for the Bernoulli distribution — bernoulli","text":"Functions involved making inferences probability success Bernoulli distribution.","code":""},{"path":"https://github.com/paulnorthrop/lax/reference/bernoulli.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Inference for the Bernoulli distribution — bernoulli","text":"","code":"fit_bernoulli(data)  # S3 method for class 'bernoulli' logLikVec(object, pars = NULL, ...)  # S3 method for class 'bernoulli' nobs(object, ...)  # S3 method for class 'bernoulli' coef(object, ...)  # S3 method for class 'bernoulli' vcov(object, ...)  # S3 method for class 'bernoulli' logLik(object, ...)  # S3 method for class 'bernoulli' alogLik(x, cluster = NULL, use_vcov = TRUE, ...)"},{"path":"https://github.com/paulnorthrop/lax/reference/bernoulli.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Inference for the Bernoulli distribution — bernoulli","text":"data numeric vector outcomes Bernoulli trials: 0 failure, 1 success.  Alternatively, logical vector FALSE failure TRUE success. pars numeric parameter vector length 1 containing value Bernoulli success probability. ... arguments passed functions sandwich package meat (cluster = NULL), meatCL (cluster NULL). x, object fitted model object returned fit_bernoulli(). cluster vector factor indicating cluster observation data originates. use_vcov logical scalar.  use vcov S3 method x (exists) estimate Hessian independence loglikelihood passed argument H adjust_loglik? Otherwise, H estimated inside adjust_loglik using optimHess.","code":""},{"path":"https://github.com/paulnorthrop/lax/reference/bernoulli.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Inference for the Bernoulli distribution — bernoulli","text":"fit_bernoulli returns object class \"bernoulli\", list components: logLik, mle, nobs, vcov, data, obs_data, data input data obs_data input data missing values removed, using na.omit. logLikVec.bernoulli returns object class \"logLikVec\", vector length length(data) containing loglikelihood contributions individual observations data.","code":""},{"path":"https://github.com/paulnorthrop/lax/reference/bernoulli.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Inference for the Bernoulli distribution — bernoulli","text":"fit_bernoulli: fit Bernoulli distribution logLikVec.bernoulli: calculates contributions loglikelihood based Bernoulli distribution.  loglikelihood calculated additive constant. nobs, coef, vcov logLik methods provided.","code":""},{"path":[]},{"path":"https://github.com/paulnorthrop/lax/reference/bernoulli.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Inference for the Bernoulli distribution — bernoulli","text":"","code":"# Set up data x <- exdex::newlyn u <- quantile(x, probs = 0.9) exc <- x > u  # Fit a Bernoulli distribution fit <- fit_bernoulli(exc)  # Calculate the loglikelihood at the MLE res <- logLikVec(fit)  # The logLik method sums the individual loglikelihood contributions. logLik(res) #> 'log Lik.' -939.9109 (df=1)  # nobs, coef, vcov, logLik methods for objects returned from fit_bernoulli() nobs(fit) #> [1] 2894 coef(fit) #>       prob  #> 0.09986178  vcov(fit) #>              prob #> prob 3.106061e-05 logLik(fit) #> 'log Lik.' -939.9109 (df=1)  # Adjusted loglikelihood # Create 5 clusters each corresponding approximately to 1 year of data cluster <- rep(1:5, each = 579)[-1] afit <- alogLik(fit, cluster = cluster, cadjust = FALSE) summary(afit) #>          MLE       SE adj. SE #> prob 0.09986 0.005573 0.01831"},{"path":"https://github.com/paulnorthrop/lax/reference/eva.html","id":null,"dir":"Reference","previous_headings":"","what":"Loglikelihood adjustment for eva fits — eva","title":"Loglikelihood adjustment for eva fits — eva","text":"S3 alogLik method perform loglikelihood adjustment fitted extreme value model objects returned functions gevrFit gpdFit eva package.","code":""},{"path":"https://github.com/paulnorthrop/lax/reference/eva.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Loglikelihood adjustment for eva fits — eva","text":"","code":"# S3 method for class 'gevrFit' alogLik(x, cluster = NULL, use_vcov = TRUE, ...)  # S3 method for class 'gpdFit' alogLik(x, cluster = NULL, use_vcov = TRUE, ...)"},{"path":"https://github.com/paulnorthrop/lax/reference/eva.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Loglikelihood adjustment for eva fits — eva","text":"x fitted model object certain associated S3 methods. See Details. cluster vector factor indicating cluster   respective log-likelihood contributions loglik originate.   length cluster must consistent estfun   method used estimation 'meat' V sandwich   estimator covariance matrix parameters passed   adjust_loglik.  cases, cluster   must length equal number observations data.    exception GP () model (binom = FALSE),   cluster may either contain value observation raw   data, threshold exceedance data. cluster supplied (NULL)   assumed observation forms cluster.   See Details details. use_vcov logical scalar.  use vcov S3 method x (exists) estimate Hessian independence loglikelihood passed argument H adjust_loglik? Otherwise, H estimated inside adjust_loglik using optimHess. ... arguments passed functions sandwich package meat (cluster = NULL), meatCL (cluster NULL).","code":""},{"path":"https://github.com/paulnorthrop/lax/reference/eva.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Loglikelihood adjustment for eva fits — eva","text":"object inheriting class \"chandwich\".  See   adjust_loglik.   class(x) vector length 5. first 3 components   c(\"lax\", \"chandwich\", \"eva\").   4th component depends model fitted.   \"rlarg\" gevrFit used;   \"gpd\" gpdFit used.   5th component   \"stat\" covariates mode   \"nonstat\" otherwise.","code":""},{"path":"https://github.com/paulnorthrop/lax/reference/eva.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Loglikelihood adjustment for eva fits — eva","text":"See alogLik details. stationary case (covariates) function   gevrFit gpdFit eva   package offer standard errors based expected information   observed information, via argument information.  contrast,   alogLik() always bases calculations observed information   matrix. Therefore, unadjusted standard errors resulting   alogLik() may different corresponding standard errors    gevrFit gpdFit. gevrFit GEV fits (gumbel = FALSE)   supported.","code":""},{"path":"https://github.com/paulnorthrop/lax/reference/eva.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Loglikelihood adjustment for eva fits — eva","text":"Chandler, R. E. Bate, S. (2007). Inference clustered   data using independence loglikelihood. Biometrika,   94(1), 167-183. doi:10.1093/biomet/asm015 Suveges, M. Davison, . C. (2010) Model   misspecification peaks threshold analysis, Annals   Applied Statistics, 4(1), 203-221.   doi:10.1214/09-AOAS292 Zeileis (2006) Object-Oriented Computation Sandwich   Estimators.  Journal Statistical Software, 16, 1-16.   doi:10.18637/jss.v016.i09","code":""},{"path":[]},{"path":"https://github.com/paulnorthrop/lax/reference/eva.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Loglikelihood adjustment for eva fits — eva","text":"","code":"# We need the eva package got_eva <- requireNamespace(\"eva\", quietly = TRUE)  if (got_eva) {   library(eva)   # An example from the eva::gpdFit documentation   set.seed(7)   x <- eva::rgpd(2000, loc = 0, scale = 2, shape = 0.2)   mle_fit <- eva::gpdFit(x, threshold = 4, method = \"mle\")   adj_mle_fit <- alogLik(mle_fit)   summary(adj_mle_fit)    # Another example from the eva::gpdFit documentation   # A linear trend in the scale parameter   set.seed(7)   n <- 300   x2 <- eva::rgpd(n, loc = 0, scale = 1 + 1:n / 200, shape = 0)   covs <- as.data.frame(seq(1, n, 1))   names(covs) <- c(\"Trend1\")   result1 <- eva::gpdFit(x2, threshold = 0, scalevars = covs,                          scaleform = ~ Trend1)   adj_result1 <- alogLik(result1)   summary(adj_result1)    # An example from the eva::gevrFit documentation   set.seed(7)   x1 <- eva::rgevr(500, 1, loc = 0.5, scale = 1, shape = 0.3)   result1 <- eva::gevrFit(x1, method = \"mle\")   adj_result1 <- alogLik(result1)   summary(adj_result1)    # Another example from the eva::gevrFit documentation   # A linear trend in the location and scale parameter   n <- 100   r <- 10   x2 <- eva::rgevr(n, r, loc = 100 + 1:n / 50,  scale = 1 + 1:n / 300,                    shape = 0)   covs <- as.data.frame(seq(1, n, 1))   names(covs) <- c(\"Trend1\")   # Create some unrelated covariates   covs$Trend2 <- rnorm(n)   covs$Trend3 <- 30 * runif(n)   result2 <- eva::gevrFit(data = x2, method = \"mle\", locvars = covs,                           locform = ~ Trend1 + Trend2*Trend3,                           scalevars = covs, scaleform = ~ Trend1)   adj_result2 <- alogLik(result2)   summary(adj_result2) } #>  #> Attaching package: 'eva' #> The following objects are masked from 'package:evd': #>  #>     dgpd, pgev, pgpd, qgev, qgpd, rgpd #>                               MLE       SE  adj. SE #> Location (Intercept)   100.200000 0.199200 0.229000 #> Location Trend1          0.018110 0.003192 0.003304 #> Location Trend2         -0.004186 0.063170 0.066540 #> Location Trend3         -0.003237 0.003934 0.003736 #> Location Trend2:Trend3  -0.001259 0.004247 0.004489 #> Scale (Intercept)        1.123000 0.092090 0.115700 #> Scale Trend1             0.002235 0.001208 0.001218 #> Shape (Intercept)        0.034370 0.030470 0.030090"},{"path":"https://github.com/paulnorthrop/lax/reference/evd.html","id":null,"dir":"Reference","previous_headings":"","what":"Loglikelihood adjustment for evd fits — evd","title":"Loglikelihood adjustment for evd fits — evd","text":"S3 alogLik method perform loglikelihood adjustment fitted extreme value model objects returned functions fgev fpot evd package. x returned fgev call must used prob = NULL.","code":""},{"path":"https://github.com/paulnorthrop/lax/reference/evd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Loglikelihood adjustment for evd fits — evd","text":"","code":"# S3 method for class 'evd' alogLik(x, cluster = NULL, use_vcov = TRUE, ...)"},{"path":"https://github.com/paulnorthrop/lax/reference/evd.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Loglikelihood adjustment for evd fits — evd","text":"x fitted model object certain associated S3 methods. See Details. cluster vector factor indicating cluster   respective log-likelihood contributions loglik originate.   length cluster must consistent estfun   method used estimation 'meat' V sandwich   estimator covariance matrix parameters passed   adjust_loglik.  cases, cluster   must length equal number observations data.    exception GP () model (binom = FALSE),   cluster may either contain value observation raw   data, threshold exceedance data. cluster supplied (NULL)   assumed observation forms cluster.   See Details details. use_vcov logical scalar.  use vcov S3 method x (exists) estimate Hessian independence loglikelihood passed argument H adjust_loglik? Otherwise, H estimated inside adjust_loglik using optimHess. ... arguments passed functions sandwich package meat (cluster = NULL), meatCL (cluster NULL).","code":""},{"path":"https://github.com/paulnorthrop/lax/reference/evd.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Loglikelihood adjustment for evd fits — evd","text":"object inheriting class \"chandwich\".  See   adjust_loglik.   class(x) vector length 5. first 3 components   c(\"lax\", \"chandwich\", \"evd\").   remaining 2 components depend model fitted.   fgev used components   c(\"gev\", \"stat\") nsloc NULL   c(\"gev\", \"nonstat\") nsloc NULL.   fpot used components   c(\"pot\", \"gpd\") model \"gpd\"   c(\"pot\", \"pp\") model \"pp\".","code":""},{"path":"https://github.com/paulnorthrop/lax/reference/evd.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Loglikelihood adjustment for evd fits — evd","text":"See alogLik details.","code":""},{"path":"https://github.com/paulnorthrop/lax/reference/evd.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Loglikelihood adjustment for evd fits — evd","text":"Chandler, R. E. Bate, S. (2007). Inference clustered   data using independence loglikelihood. Biometrika,   94(1), 167-183. doi:10.1093/biomet/asm015 Suveges, M. Davison, . C. (2010) Model   misspecification peaks threshold analysis, Annals   Applied Statistics, 4(1), 203-221.   doi:10.1214/09-AOAS292 Zeileis (2006) Object-Oriented Computation Sandwich   Estimators.  Journal Statistical Software, 16, 1-16.   doi:10.18637/jss.v016.i09","code":""},{"path":[]},{"path":"https://github.com/paulnorthrop/lax/reference/evd.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Loglikelihood adjustment for evd fits — evd","text":"","code":"# We need the evd package got_evd <- requireNamespace(\"evd\", quietly = TRUE)  if (got_evd) {   library(evd)   # An example from the evd::fgev documentation   set.seed(3082019)   uvdata <- evd::rgev(100, loc = 0.13, scale = 1.1, shape = 0.2)   M1 <- evd::fgev(uvdata, nsloc = (-49:50)/100)   adj_fgev <- alogLik(M1)   summary(adj_fgev)    # An example from Chandler and Bate (2007)   owfit <- fgev(ow$temp, nsloc = ow$loc)   adj_owfit <- alogLik(owfit, cluster = ow$year)   summary(adj_owfit)    # An example from the evd::fpot documentation   set.seed(3082019)   uvdata <- evd::rgpd(100, loc = 0, scale = 1.1, shape = 0.2)   M1 <- fpot(uvdata, 1)   adj_fpot <- alogLik(M1)   summary(adj_fpot)   # Fit using the pp model, rather than the gpd   M1 <- fpot(uvdata, 1, model = \"pp\", npp = 365)   adj_fpot <- alogLik(M1)   summary(adj_fpot) } #>           MLE     SE adj. SE #> loc   13.6100 5.6170  3.9330 #> scale  3.8420 3.2740  2.4440 #> shape  0.1913 0.1964  0.1617"},{"path":"https://github.com/paulnorthrop/lax/reference/evir.html","id":null,"dir":"Reference","previous_headings":"","what":"Loglikelihood adjustment for evir fits — evir","title":"Loglikelihood adjustment for evir fits — evir","text":"S3 alogLik method perform loglikelihood adjustment fitted extreme value model objects returned functions gev, gpd pot evir package. x returned pot model need re-fitted using pot_refit.","code":""},{"path":"https://github.com/paulnorthrop/lax/reference/evir.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Loglikelihood adjustment for evir fits — evir","text":"","code":"# S3 method for class 'gev' alogLik(x, cluster = NULL, use_vcov = TRUE, ...)  # S3 method for class 'gpd' alogLik(x, cluster = NULL, use_vcov = TRUE, ...)  # S3 method for class 'potd' alogLik(x, cluster = NULL, use_vcov = TRUE, ...)"},{"path":"https://github.com/paulnorthrop/lax/reference/evir.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Loglikelihood adjustment for evir fits — evir","text":"x fitted model object certain associated S3 methods. See Details. cluster vector factor indicating cluster   respective log-likelihood contributions loglik originate.   length cluster must consistent estfun   method used estimation 'meat' V sandwich   estimator covariance matrix parameters passed   adjust_loglik.  cases, cluster   must length equal number observations data.    exception GP () model (binom = FALSE),   cluster may either contain value observation raw   data, threshold exceedance data. cluster supplied (NULL)   assumed observation forms cluster.   See Details details. use_vcov logical scalar.  use vcov S3 method x (exists) estimate Hessian independence loglikelihood passed argument H adjust_loglik? Otherwise, H estimated inside adjust_loglik using optimHess. ... arguments passed functions sandwich package meat (cluster = NULL), meatCL (cluster NULL).","code":""},{"path":"https://github.com/paulnorthrop/lax/reference/evir.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Loglikelihood adjustment for evir fits — evir","text":"object inheriting class \"chandwich\".  See   adjust_loglik.   class(x) vector length 5. first 3 components   c(\"lax\", \"chandwich\", \"evir\").   remaining 2 components depend model fitted.   gev used components   c(\"gev\", \"stat\").   gpd used components   c(\"gpd\", \"stat\").   pot_refit used components   c(\"potd\", \"stat\").","code":""},{"path":"https://github.com/paulnorthrop/lax/reference/evir.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Loglikelihood adjustment for evir fits — evir","text":"See alogLik details. pot used x contain raw data alogLik needs.  model need re-fitted using pot_refit user prompted error message produced alogLik.","code":""},{"path":"https://github.com/paulnorthrop/lax/reference/evir.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Loglikelihood adjustment for evir fits — evir","text":"Chandler, R. E. Bate, S. (2007). Inference clustered   data using independence loglikelihood. Biometrika,   94(1), 167-183. doi:10.1093/biomet/asm015 Suveges, M. Davison, . C. (2010) Model   misspecification peaks threshold analysis, Annals   Applied Statistics, 4(1), 203-221.   doi:10.1214/09-AOAS292 Zeileis (2006) Object-Oriented Computation Sandwich   Estimators.  Journal Statistical Software, 16, 1-16.   doi:10.18637/jss.v016.i09","code":""},{"path":[]},{"path":"https://github.com/paulnorthrop/lax/reference/evir.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Loglikelihood adjustment for evir fits — evir","text":"","code":"# We need the evir package got_evir <- requireNamespace(\"evir\", quietly = TRUE) if (got_evir) {   library(evir)   # An example from the evir::gev documentation   data(bmw)   out <- gev(bmw, \"month\")   adj_out <- alogLik(out)   summary(adj_out)    # An example from the evir::gpd documentation   data(danish)   out <- gpd(danish, 10)   adj_out <- alogLik(out)   summary(adj_out)    # An example from the evir::pot documentation   # We use lax::pot_refit() to return the input data   out <- pot_refit(danish, 10)   adj_out <- alogLik(out)   summary(adj_out) } #>  #> Attaching package: 'evir' #> The following objects are masked from 'package:eva': #>  #>     dgpd, pgev, pgpd, qgev, qgpd, rgpd #> The following object is masked from 'package:extRemes': #>  #>     decluster #> The following objects are masked from 'package:evd': #>  #>     dgev, dgpd, pgev, pgpd, qgev, qgpd, rgev, rgpd #>           MLE     SE adj. SE #> xi     0.4972 0.1359  0.1435 #> sigma  1.1610 0.6888  0.7086 #> mu    -1.6960 3.4380  3.4270"},{"path":"https://github.com/paulnorthrop/lax/reference/extRemes.html","id":null,"dir":"Reference","previous_headings":"","what":"Loglikelihood adjustment for extRemes fits — extRemes","title":"Loglikelihood adjustment for extRemes fits — extRemes","text":"S3 alogLik method perform loglikelihood adjustment fitted extreme value model objects returned function fevd extRemes package. model must fitted using maximum likelihood estimation.","code":""},{"path":"https://github.com/paulnorthrop/lax/reference/extRemes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Loglikelihood adjustment for extRemes fits — extRemes","text":"","code":"# S3 method for class 'fevd' alogLik(x, cluster = NULL, use_vcov = TRUE, ...)"},{"path":"https://github.com/paulnorthrop/lax/reference/extRemes.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Loglikelihood adjustment for extRemes fits — extRemes","text":"x fitted model object certain associated S3 methods. See Details. cluster vector factor indicating cluster   respective log-likelihood contributions loglik originate.   length cluster must consistent estfun   method used estimation 'meat' V sandwich   estimator covariance matrix parameters passed   adjust_loglik.  cases, cluster   must length equal number observations data.    exception GP () model (binom = FALSE),   cluster may either contain value observation raw   data, threshold exceedance data. cluster supplied (NULL)   assumed observation forms cluster.   See Details details. use_vcov logical scalar.  use vcov S3 method x (exists) estimate Hessian independence loglikelihood passed argument H adjust_loglik? Otherwise, H estimated inside adjust_loglik using optimHess. ... arguments passed functions sandwich package meat (cluster = NULL), meatCL (cluster NULL).","code":""},{"path":"https://github.com/paulnorthrop/lax/reference/extRemes.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Loglikelihood adjustment for extRemes fits — extRemes","text":"object inheriting class \"chandwich\".  See   adjust_loglik.   class(x) vector length 5. first 3 components   c(\"lax\", \"chandwich\", \"extRemes\").   remaining 2 components depend model fitted.   4th component : \"gev\" x$type = \"GEV\"   x$type = \"Gumbel\"; \"gp\" x$type = \"GP\"   x$type = \"Exponential\"; \"pp\" x$type = \"PP\".   5th component   \"stat\" .fixedfevd = TRUE   \"nonstat\" .fixedfevd = FALSE.","code":""},{"path":"https://github.com/paulnorthrop/lax/reference/extRemes.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Loglikelihood adjustment for extRemes fits — extRemes","text":"See alogLik details.","code":""},{"path":"https://github.com/paulnorthrop/lax/reference/extRemes.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Loglikelihood adjustment for extRemes fits — extRemes","text":"Chandler, R. E. Bate, S. (2007). Inference clustered   data using independence loglikelihood. Biometrika,   94(1), 167-183. doi:10.1093/biomet/asm015 Suveges, M. Davison, . C. (2010) Model   misspecification peaks threshold analysis, Annals   Applied Statistics, 4(1), 203-221.   doi:10.1214/09-AOAS292 Zeileis (2006) Object-Oriented Computation Sandwich   Estimators.  Journal Statistical Software, 16, 1-16.   doi:10.18637/jss.v016.i09","code":""},{"path":[]},{"path":"https://github.com/paulnorthrop/lax/reference/extRemes.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Loglikelihood adjustment for extRemes fits — extRemes","text":"","code":"# We need the extRemes and distillery packages got_extRemes <- requireNamespace(\"extRemes\", quietly = TRUE) got_distillery <- requireNamespace(\"distillery\", quietly = TRUE)  if (got_extRemes & got_distillery) {   library(extRemes)   library(distillery)   # Examples from the extRemes::fevd documentation   data(PORTw)    # GEV   fit0 <- fevd(TMX1, PORTw, units = \"deg C\", use.phi = TRUE)   adj_fit0 <- alogLik(fit0)   summary(adj_fit0)    # GEV regression   fitPORTstdmax <- fevd(TMX1, PORTw, scale.fun = ~STDTMAX, use.phi = TRUE)   adj_fit1 <- alogLik(fitPORTstdmax)   summary(adj_fit1)   fitPORTstdmax2 <- fevd(TMX1, PORTw, location.fun = ~STDTMAX,                          scale.fun = ~STDTMAX, use.phi = TRUE)   adj_fit2 <- alogLik(fitPORTstdmax2)   summary(adj_fit2)   anova(adj_fit0, adj_fit1)   anova(adj_fit1, adj_fit2)   anova(adj_fit0, adj_fit2)   anova(adj_fit0, adj_fit1, adj_fit2)    # Gumbel   fit0 <- fevd(TMX1, PORTw, type = \"Gumbel\", units = \"deg C\")   adj_fit0 <- alogLik(fit0)   summary(adj_fit0)    # GP   data(damage)   fit1 <- fevd(Dam, damage, threshold = 6, type = \"GP\",                time.units = \"2.05/year\")   adj_fit1 <- alogLik(fit1)   summary(adj_fit1)    # Exponential   fit0 <- fevd(Dam, damage, threshold = 6, type=\"Exponential\",                time.units = \"2.05/year\")   adj_fit0 <- alogLik(fit0)   summary(adj_fit0)    # GP non-constant threshold   data(Fort)   fit <- fevd(Prec, Fort, threshold = 0.475,               threshold.fun = ~I(-0.15 * cos(2 * pi * month / 12)),               type = \"GP\")   adj_fit <- alogLik(fit)   summary(adj_fit)    # Exponential non-constant threshold   fit <- fevd(Prec, Fort, threshold = 0.475,               threshold.fun = ~I(-0.15 * cos(2 * pi * month / 12)),               type = \"Exponential\")   adj_fit <- alogLik(fit)   summary(adj_fit)    # PP model   fit <- fevd(Prec, Fort, threshold = 0.475, type = \"PP\", units = \"inches\")   adj_fit <- alogLik(fit)   summary(adj_fit)    # PP non-constant threshold   fit <- fevd(Prec, Fort, threshold = 0.475,               threshold.fun=~I(-0.15 * cos(2 * pi * month / 12)),               type = \"PP\")   adj_fit <- alogLik(fit)   summary(adj_fit) } #>           MLE      SE adj. SE #> mu0    1.4200 0.04277 0.04286 #> sigma0 0.5226 0.03129 0.03075 #> xi0    0.1162 0.03791 0.03404"},{"path":"https://github.com/paulnorthrop/lax/reference/fExtremes.html","id":null,"dir":"Reference","previous_headings":"","what":"Loglikelihood adjustment for fExtremes fits — fExtremes","title":"Loglikelihood adjustment for fExtremes fits — fExtremes","text":"S3 alogLik method perform loglikelihood adjustment fitted extreme value model objects returned functions gevFit, gumbelFit gpdFit fExtremes package. model must fitted using maximum likelihood estimation.","code":""},{"path":"https://github.com/paulnorthrop/lax/reference/fExtremes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Loglikelihood adjustment for fExtremes fits — fExtremes","text":"","code":"# S3 method for class 'fGEVFIT' alogLik(x, cluster = NULL, use_vcov = TRUE, ...)  # S3 method for class 'fGPDFIT' alogLik(x, cluster = NULL, use_vcov = TRUE, ...)"},{"path":"https://github.com/paulnorthrop/lax/reference/fExtremes.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Loglikelihood adjustment for fExtremes fits — fExtremes","text":"x fitted model object certain associated S3 methods. See Details. cluster vector factor indicating cluster   respective log-likelihood contributions loglik originate.   length cluster must consistent estfun   method used estimation 'meat' V sandwich   estimator covariance matrix parameters passed   adjust_loglik.  cases, cluster   must length equal number observations data.    exception GP () model (binom = FALSE),   cluster may either contain value observation raw   data, threshold exceedance data. cluster supplied (NULL)   assumed observation forms cluster.   See Details details. use_vcov logical scalar.  use vcov S3 method x (exists) estimate Hessian independence loglikelihood passed argument H adjust_loglik? Otherwise, H estimated inside adjust_loglik using optimHess. ... arguments passed functions sandwich package meat (cluster = NULL), meatCL (cluster NULL).","code":""},{"path":"https://github.com/paulnorthrop/lax/reference/fExtremes.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Loglikelihood adjustment for fExtremes fits — fExtremes","text":"object inheriting class \"chandwich\".  See   adjust_loglik.   class(x) vector length 5. first 3 components   c(\"lax\", \"chandwich\", \"fExtremes\").   remaining 2 components depend model fitted.   gevFit   gumbelFit used   components c(\"gev\", \"stat\").   gpdFit used   components c(\"gpd\", \"stat\").","code":""},{"path":"https://github.com/paulnorthrop/lax/reference/fExtremes.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Loglikelihood adjustment for fExtremes fits — fExtremes","text":"See alogLik details.","code":""},{"path":"https://github.com/paulnorthrop/lax/reference/fExtremes.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Loglikelihood adjustment for fExtremes fits — fExtremes","text":"Chandler, R. E. Bate, S. (2007). Inference clustered   data using independence loglikelihood. Biometrika,   94(1), 167-183. doi:10.1093/biomet/asm015 Suveges, M. Davison, . C. (2010) Model   misspecification peaks threshold analysis, Annals   Applied Statistics, 4(1), 203-221.   doi:10.1214/09-AOAS292 Zeileis (2006) Object-Oriented Computation Sandwich   Estimators.  Journal Statistical Software, 16, 1-16.   doi:10.18637/jss.v016.i09","code":""},{"path":[]},{"path":"https://github.com/paulnorthrop/lax/reference/fExtremes.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Loglikelihood adjustment for fExtremes fits — fExtremes","text":"","code":"# We need the fExtremes package got_fExtremes <- requireNamespace(\"fExtremes\", quietly = TRUE) if (got_fExtremes) {   library(fExtremes)    # GEV   # An example from the fExtremes::gevFit documentation   set.seed(4082019)   x <- fExtremes::gevSim(model = list(xi=0.25, mu=0, beta=1), n = 1000)   # Fit GEV distribution by maximum likelihood estimation   fit <- fExtremes::gevFit(x)   adj_fit <- alogLik(fit)   summary(adj_fit)    # GP   # An example from the fExtremes::gpdFit documentation   # Simulate GP data   x <- fExtremes::gpdSim(model = list(xi = 0.25, mu = 0, beta = 1), n = 1000)   # Fit GP distribution by maximum likelihood estimation   fit <- fExtremes::gpdFit(x, u = min(x))   adj_fit <- alogLik(fit)   summary(adj_fit) } #>  #> Attaching package: 'fExtremes' #> The following objects are masked from 'package:evir': #>  #>     dgev, dgpd, pgev, pgpd, qgev, qgpd, rgev, rgpd #> The following objects are masked from 'package:eva': #>  #>     dgpd, gpdFit, mrlPlot, pgev, pgpd, qgev, qgpd, rgpd #> The following objects are masked from 'package:evd': #>  #>     dgev, dgpd, pgev, pgpd, qgev, qgpd, rgev, rgpd #>         MLE      SE adj. SE #> xi   0.2514 0.03844 0.04026 #> beta 0.9989 0.04909 0.04852"},{"path":"https://github.com/paulnorthrop/lax/reference/ismev.html","id":null,"dir":"Reference","previous_headings":"","what":"Loglikelihood adjustment for ismev fits — ismev","title":"Loglikelihood adjustment for ismev fits — ismev","text":"S3 alogLik method perform loglikelihood adjustment fitted extreme value model objects returned functions gev.fit, gpd.fit, pp.fit rlarg.fit ismev package.  regression modelling used model need re-fitted, see ismev_refits.","code":""},{"path":"https://github.com/paulnorthrop/lax/reference/ismev.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Loglikelihood adjustment for ismev fits — ismev","text":"","code":"# S3 method for class 'gev.fit' alogLik(x, cluster = NULL, use_vcov = TRUE, ...)  # S3 method for class 'pp.fit' alogLik(x, cluster = NULL, use_vcov = TRUE, ...)  # S3 method for class 'gpd.fit' alogLik(   x,   cluster = NULL,   use_vcov = TRUE,   binom = FALSE,   k,   inc_cens = TRUE,   ... )  # S3 method for class 'rlarg.fit' alogLik(x, cluster = NULL, use_vcov = TRUE, ...)"},{"path":"https://github.com/paulnorthrop/lax/reference/ismev.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Loglikelihood adjustment for ismev fits — ismev","text":"x fitted model object certain associated S3 methods. See Details. cluster vector factor indicating cluster   respective log-likelihood contributions loglik originate.   length cluster must consistent estfun   method used estimation 'meat' V sandwich   estimator covariance matrix parameters passed   adjust_loglik.  cases, cluster   must length equal number observations data.    exception GP () model (binom = FALSE),   cluster may either contain value observation raw   data, threshold exceedance data. cluster supplied (NULL)   assumed observation forms cluster.   See Details details. use_vcov logical scalar.  use vcov S3 method x (exists) estimate Hessian independence loglikelihood passed argument H adjust_loglik? Otherwise, H estimated inside adjust_loglik using optimHess. ... arguments passed functions sandwich package meat (cluster = NULL), meatCL (cluster NULL). binom logical scalar.  option relevant GP models available stationary (covariates) case. binom = FALSE loglikelihood adjustment performed using GP model. binom = TRUE loglikelihood adjustment also performed inferences probability threshold exceedance, using Bernoulli model instances threshold exceedance. k non-negative integer scalar.  option relevant GP models available stationary (covariates) case.  k supplied passed run parameter \\(K\\) kgaps making inferences extremal index \\(\\theta\\) using \\(K\\)-gaps model Suveges Davison (2010). inc_cens logical scalar.  argument relevant k supplied.  Passed kgaps indicate whether include censored inter-exceedance times, relating first last observations.","code":""},{"path":"https://github.com/paulnorthrop/lax/reference/ismev.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Loglikelihood adjustment for ismev fits — ismev","text":"object inheriting class \"chandwich\".  See   adjust_loglik. class(x) vector length 5. first 3 components   c(\"lax\", \"chandwich\", \"ismev\").   remaining 2 components depend model fitted.   4th component :   \"gev\" gev.fit   (gev_refit) used;   \"gpd\" gpd.fit   (gpd_refit) used;   \"pp\" pp.fit   (pp_refit) used;   \"rlarg\" rlarg.fit   (rlarg_refit) used.   5th component   \"stat\" x$trans = FALSE   \"nonstat\" x$trans = TRUE.","code":""},{"path":"https://github.com/paulnorthrop/lax/reference/ismev.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Loglikelihood adjustment for ismev fits — ismev","text":"See alogLik details. regression modelling used ismev functions gev.fit, gpd.fit, pp.fit rlarg.fit return residuals alogLik needs raw data. model need re-fitted, using one functions ismev_refits, user prompted error message produced alogLik.","code":""},{"path":"https://github.com/paulnorthrop/lax/reference/ismev.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Loglikelihood adjustment for ismev fits — ismev","text":"Chandler, R. E. Bate, S. (2007). Inference clustered   data using independence loglikelihood. Biometrika,   94(1), 167-183. doi:10.1093/biomet/asm015 Suveges, M. Davison, . C. (2010) Model   misspecification peaks threshold analysis, Annals   Applied Statistics, 4(1), 203-221.   doi:10.1214/09-AOAS292 Zeileis (2006) Object-Oriented Computation Sandwich   Estimators.  Journal Statistical Software, 16, 1-16.   doi:10.18637/jss.v016.i09","code":""},{"path":[]},{"path":"https://github.com/paulnorthrop/lax/reference/ismev.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Loglikelihood adjustment for ismev fits — ismev","text":"","code":"# We need the ismev package got_ismev <- requireNamespace(\"ismev\", quietly = TRUE)  if (got_ismev) {   library(ismev)    # GEV model -----    # An example from the ismev::gev.fit documentation   gev_fit <- gev.fit(revdbayes::portpirie, show = FALSE)   adj_gev_fit <- alogLik(gev_fit)   summary(adj_gev_fit)    # An example from chapter 6 of Coles (2001)   data(fremantle)   xdat <- fremantle[, \"SeaLevel\"]   # Set year 1897 to 1 for consistency with page 113 of Coles (2001)   ydat <- cbind(fremantle[, \"Year\"] - 1896, fremantle[, \"SOI\"])   gev_fit <- gev_refit(xdat, ydat, mul = 1:2, show = FALSE)   adj_gev_fit <- alogLik(gev_fit)   summary(adj_gev_fit)    # An example from Chandler and Bate (2007)   gev_fit <- gev_refit(ow$temp, ow, mul = 4, sigl = 4, shl = 4,                        show = FALSE)   adj_gev_fit <- alogLik(gev_fit, cluster = ow$year)   summary(adj_gev_fit)   # Get closer to the values reported in Table 2 of Chandler and Bate (2007)   gev_fit <- gev_refit(ow$temp, ow, mul = 4, sigl = 4, shl = 4,                        show = FALSE, method = \"BFGS\")   # Call sandwich::meatCL() with cadjust = FALSE   adj_gev_fit <- alogLik(gev_fit, cluster = ow$year, cadjust = FALSE)   summary(adj_gev_fit)    # GP model -----    # An example from the ismev::gpd.fit documentation   # \\donttest{   data(rain)   rain_fit <- gpd.fit(rain, 10, show = FALSE)   adj_rain_fit <- alogLik(rain_fit)   summary(adj_rain_fit)   # Continuing to the regression example on page 119 of Coles (2001)   ydat <- as.matrix((1:length(rain)) / length(rain))   reg_rain_fit <- gpd_refit(rain, 30, ydat = ydat, sigl = 1, siglink = exp,                             show = FALSE)   adj_reg_rain_fit <- alogLik(reg_rain_fit)   summary(adj_reg_rain_fit)   # }   # Binomial-GP model -----    # Use Newlyn seas surges data from the exdex package   surges <- exdex::newlyn   u <- quantile(surges, probs = 0.9)   newlyn_fit <- gpd.fit(surges, u, show = FALSE)   # Create 5 clusters each corresponding approximately to 1 year of data   cluster <- rep(1:5, each = 579)[-1]   adj_newlyn_fit <- alogLik(newlyn_fit, cluster = cluster, binom = TRUE,                             cadjust = FALSE)   summary(adj_newlyn_fit)   summary(attr(adj_newlyn_fit, \"pu_aloglik\"))    # Add inference about the extremal index theta, using K = 1   adj_newlyn_theta <- alogLik(newlyn_fit, cluster = cluster, binom = TRUE,                               k = 1, cadjust = FALSE)   summary(attr(adj_newlyn_theta, \"theta\"))    # PP model -----    # An example from the ismev::pp.fit documentation   data(rain)   # Start from the mle to save time   init <- c(40.55755732, 8.99195409, 0.05088103)   muinit <- init[1]   siginit <- init[2]   shinit <- init[3]   rain_fit <- pp_refit(rain, 10, muinit = muinit, siginit = siginit,                        shinit = shinit, show = FALSE)   adj_rain_fit <- alogLik(rain_fit)   summary(adj_rain_fit)    # An example from chapter 7 of Coles (2001).   # Code from demo ismev::wooster.temps   data(wooster)   x <- seq(along = wooster)   usin <- function(x, a, b, d) {     return(a + b * sin(((x - d) * 2 * pi) / 365.25))   }   wu <- usin(x, -30, 25, -75)   ydat <- cbind(sin(2 * pi * x / 365.25), cos(2 * pi *x / 365.25))   # Start from the mle to save time   init <- c(-15.3454188, 9.6001844, 28.5493828, 0.5067104, 0.1023488,             0.5129783, -0.3504231)   muinit <- init[1:3]   siginit <- init[4:6]   shinit <- init[7]   wooster.pp <- pp_refit(-wooster, threshold = wu, ydat = ydat, mul = 1:2,                          sigl = 1:2, siglink = exp, method = \"BFGS\",                          muinit = muinit, siginit = siginit, shinit = shinit,                          show = FALSE)   adj_pp_fit <- alogLik(wooster.pp)   summary(adj_pp_fit)    # r-largest order statistics model -----    # An example based on the ismev::rlarg.fit() documentation   vdata <- revdbayes::venice   rfit <- rlarg.fit(vdata, muinit = 120.54, siginit = 12.78,                     shinit = -0.1129, show = FALSE)   adj_rfit <- alogLik(rfit)   summary(adj_rfit)    # \\donttest{   # Adapt this example to add a covariate   set.seed(30102019)   ydat <- matrix(runif(nrow(vdata)), nrow(vdata), 1)   rfit2 <- rlarg_refit(vdata, ydat = ydat, mul = 1,                        muinit = c(120.54, 0), siginit = 12.78,                        shinit = -0.1129, show = FALSE)   adj_rfit2 <- alogLik(rfit2)   summary(adj_rfit2)   # } } #> Loading required package: mgcv #> Loading required package: nlme #> This is mgcv 1.9-3. For overview type 'help(\"mgcv-package\")'. #>            MLE      SE adj. SE #> loc   122.8000 1.77100 3.17100 #> loc1   -5.5400 2.65700 4.46100 #> scale  12.6500 0.53290 0.81270 #> shape  -0.1172 0.01948 0.02741"},{"path":"https://github.com/paulnorthrop/lax/reference/ismev_refits.html","id":null,"dir":"Reference","previous_headings":"","what":"Maximum-likelihood (Re-)Fitting using the ismev package — ismev_refits","title":"Maximum-likelihood (Re-)Fitting using the ismev package — ismev_refits","text":"slightly modified versions gev.fit, gpd.fit, pp.fit rlarg.fit functions ismev package. modification add returned object regression design matrices parameters model.  , xdat, ydat, mulink, siglink, shlink matrices mumat, sigmat, shmat location, scale shape parameters gev.fit, pp.fit rlarg.fit, xdat, ydat, siglink, shlink matrices sigmat, shmat scale shape parameters gpd.fit.","code":""},{"path":"https://github.com/paulnorthrop/lax/reference/ismev_refits.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Maximum-likelihood (Re-)Fitting using the ismev package — ismev_refits","text":"","code":"gev_refit(   xdat,   ydat = NULL,   mul = NULL,   sigl = NULL,   shl = NULL,   mulink = identity,   siglink = identity,   shlink = identity,   muinit = NULL,   siginit = NULL,   shinit = NULL,   show = TRUE,   method = \"Nelder-Mead\",   maxit = 10000,   ... )  gpd_refit(   xdat,   threshold,   npy = 365,   ydat = NULL,   sigl = NULL,   shl = NULL,   siglink = identity,   shlink = identity,   siginit = NULL,   shinit = NULL,   show = TRUE,   method = \"Nelder-Mead\",   maxit = 10000,   ... )  pp_refit(   xdat,   threshold,   npy = 365,   ydat = NULL,   mul = NULL,   sigl = NULL,   shl = NULL,   mulink = identity,   siglink = identity,   shlink = identity,   muinit = NULL,   siginit = NULL,   shinit = NULL,   show = TRUE,   method = \"Nelder-Mead\",   maxit = 10000,   ... )  rlarg_refit(   xdat,   r = dim(xdat)[2],   ydat = NULL,   mul = NULL,   sigl = NULL,   shl = NULL,   mulink = identity,   siglink = identity,   shlink = identity,   muinit = NULL,   siginit = NULL,   shinit = NULL,   show = TRUE,   method = \"Nelder-Mead\",   maxit = 10000,   ... )"},{"path":"https://github.com/paulnorthrop/lax/reference/ismev_refits.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Maximum-likelihood (Re-)Fitting using the ismev package — ismev_refits","text":"xdat numeric vector data fitted. ydat matrix covariates generalized linear modelling     parameters (NULL (default) stationary     fitting). number rows length     xdat. mul, sigl, shl Numeric vectors integers, giving columns     ydat contain covariates generalized linear     modelling location, scale shape parameters repectively     (NULL (default) corresponding parameter     stationary). mulink, siglink, shlink Inverse link functions generalized     linear modelling location, scale shape parameters     repectively. muinit, siginit, shinit numeric length equal total number     parameters used model location, scale shape parameter(s),     resp.  See Details section default (NULL) initial values. show Logical; TRUE (default), print details     fit. method optimization method (see optim     details). maxit maximum number iterations. ... control parameters optimization.     passed components control argument     optim. threshold threshold; single number numeric     vector length xdat. npy number observations per year/block. r largest r order statistics used     fitted model.","code":""},{"path":"https://github.com/paulnorthrop/lax/reference/ismev_refits.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Maximum-likelihood (Re-)Fitting using the ismev package — ismev_refits","text":"Heffernan, J. E. Stephenson, . G. (2018). ismev:   Introduction Statistical Modeling Extreme Values.   R package version 1.42.   https://CRAN.R-project.org/package=ismev.","code":""},{"path":"https://github.com/paulnorthrop/lax/reference/ismev_refits.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Maximum-likelihood (Re-)Fitting using the ismev package — ismev_refits","text":"","code":"# We need the ismev package got_ismev <- requireNamespace(\"ismev\", quietly = TRUE) if (got_ismev) {   library(ismev)   fit1 <- gev.fit(revdbayes::portpirie, show = FALSE)   ls(fit1)   fit2 <- gev_refit(revdbayes::portpirie, show = FALSE)   ls(fit2)    data(rain)   fit1 <- gpd.fit(rain, 10)   ls(fit1)   fit2 <- gpd_refit(rain, 10)   ls(fit2)    fit1 <- pp.fit(rain, 10, show = FALSE)   ls(fit1)   fit2 <- pp_refit(rain, 10, show = FALSE)   ls(fit2)    data(venice)   fit1 <- rlarg.fit(venice[, -1], muinit = 120.54, siginit = 12.78,                    shinit = -0.1129, show = FALSE)   ls(fit1)   fit2 <- rlarg_refit(venice[, -1], muinit = 120.54, siginit = 12.78,                    shinit = -0.1129, show = FALSE)   ls(fit2) } #> $threshold #> [1] 10 #>  #> $nexc #> [1] 2003 #>  #> $conv #> [1] 0 #>  #> $nllh #> [1] 6123.465 #>  #> $mle #> [1] 7.43768624 0.05045225 #>  #> $rate #> [1] 0.1142547 #>  #> $se #> [1] 0.23606472 0.02256649 #>  #> $threshold #> [1] 10 #>  #> $nexc #> [1] 2003 #>  #> $conv #> [1] 0 #>  #> $nllh #> [1] 6123.465 #>  #> $mle #> [1] 7.43768624 0.05045225 #>  #> $rate #> [1] 0.1142547 #>  #> $se #> [1] 0.23606472 0.02256649 #>  #>  [1] \"conv\"    \"cov\"     \"data\"    \"link\"    \"mle\"     \"model\"   \"mulink\"  #>  [8] \"mumat\"   \"nllh\"    \"r\"       \"se\"      \"shlink\"  \"shmat\"   \"siglink\" #> [15] \"sigmat\"  \"trans\"   \"vals\"    \"xdat\""},{"path":"https://github.com/paulnorthrop/lax/reference/lax-internal.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal lax functions — lax-internal","title":"Internal lax functions — lax-internal","text":"Internal lax functions.","code":""},{"path":"https://github.com/paulnorthrop/lax/reference/lax-internal.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Internal lax functions — lax-internal","text":"","code":"adj_object(x, cluster = NULL, use_vcov = TRUE, ...)  return_level_gev(x, m, level, npy, prof, inc, type)  gev_rl_CI(x, m, level, npy, type)  gev_rl_prof(x, m, level, npy, inc, type, rl_sym)  return_level_bingp(x, m, level, npy, prof, inc, type, npy_given)  bingp_rl_CI(x, m, level, npy, type, u)  bingp_rl_prof(x, m, level, npy, inc, type, rl_sym, u)  box_cox_deriv(x, lambda = 1, lambda_tol = 1/50, poly_order = 3)  ismev_ppp(a, npy)  kgaps_loglik(theta, N0, N1, sum_qs, n_kgaps)"},{"path":"https://github.com/paulnorthrop/lax/reference/lax-internal.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Internal lax functions — lax-internal","text":"functions intended called user.","code":""},{"path":"https://github.com/paulnorthrop/lax/reference/lax-package.html","id":null,"dir":"Reference","previous_headings":"","what":"lax: Loglikelihood Adjustment for Extreme Value Models — lax-package","title":"lax: Loglikelihood Adjustment for Extreme Value Models — lax-package","text":"Performs adjusted inferences based model objects fitted, using maximum likelihood estimation, extreme value analysis packages eva, evd, evir, extRemes, fExtremes, ismev, mev, POT texmex. Univariate extreme value models, including regression models, supported. Adjusted standard errors adjusted loglikelihood provided, using chandwich package  object-oriented features  sandwich package.","code":""},{"path":"https://github.com/paulnorthrop/lax/reference/lax-package.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"lax: Loglikelihood Adjustment for Extreme Value Models — lax-package","text":"adjustment based robust sandwich estimator parameter covariance matrix, based methodology Chandler Bate (2007). can used cluster correlated data interest lies parameters marginal distributions, performing inferences robust certain types model misspecification. main function alogLik, works object-oriented way, operating fitted model objects. function performs loglikelihood adjustments using adjust_loglik. See following package-specific help pages details examples: eva, evd, evir, extRemes, fExtremes, ismev, mev, POT, texmex. See vignette(\"lax-vignette\", package = \"lax\") overview package.","code":""},{"path":"https://github.com/paulnorthrop/lax/reference/lax-package.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"lax: Loglikelihood Adjustment for Extreme Value Models — lax-package","text":"Bader, B. Yan, J. (2020). eva: Extreme Value Analysis   Goodness--Fit Testing. R package version 0.2.6.   https://CRAN.R-project.org/package=eva Belzile, L., Wadsworth, J. L., Northrop, P. J., Grimshaw, S. D.   Huser, R. (2019). mev: Multivariate Extreme Value Distributions.   R package version 1.12.2. https://github.com/lbelzile/mev/ Berger S., Graham N., Zeileis . (2017). Various Versatile   Variances: Object-Oriented Implementation Clustered Covariances R.   Technical Report 2017-12, Working Papers Economics Statistics,   Research Platform Empirical Experimental Economics, Universitat   Innsbruck. https://EconPapers.RePEc.org/RePEc:inn:wpaper:2017-12. Chandler, R. E. Bate, S. (2007). Inference clustered   data using independence loglikelihood. Biometrika,   94(1), 167-183. doi:10.1093/biomet/asm015 Gilleland, E. Katz, R. W. (2016). extRemes 2.0: Extreme   Value Analysis Package R. Journal Statistical Software,   72(8), 1-39. doi:10.18637/jss.v072.i08 Northrop, P. J. Chandler, R. E. (2018).   chandwich: Chandler-Bate Sandwich Loglikelihood Adjustment. R package   version 1.1. https://CRAN.R-project.org/package=chandwich. Pfaff, B. McNeil, . (2018). evir: Extreme Values R.   R package version 1.7-4. https://CRAN.R-project.org/package=evir Ribatet, M. Dutang, C. (2019). POT: Generalized Pareto   Distribution Peaks Threshold. R package version 1.1-7.   https://CRAN.R-project.org/package=POT Southworth, H., Heffernan, J. E. Metcalfe, P. D. (2017).   texmex: Statistical modelling extreme values. R package version 2.4.   https://CRAN.R-project.org/package=texmex. Stephenson, . G. evd: Extreme Value Distributions.   R News, 2(2):31-32, June 2002.   https://CRAN.R-project.org/doc/Rnews/ Stephenson, . G., Heffernan, J. E. Gilleland, E. (2018).   ismev: Introduction Statistical Modeling Extreme Values.   R package version 1.42. https://CRAN.R-project.org/package=ismev. Wuertz, D., Setz, T. Chalabi, Y. (2017). fExtremes:   Rmetrics - Modelling Extreme Events Finance. R package version   3042.82. https://CRAN.R-project.org/package=fExtremes Zeileis . (2004). Econometric Computing HC HAC   Covariance Matrix Estimators. Journal Statistical Software,   11(10), 1-17. doi:10.18637/jss.v011.i10 . Zeileis . (2006). Object-Oriented Computation Sandwich   Estimators. Journal Statistical Software, 16(9),   1-16. doi:10.18637/jss.v016.i09 .","code":""},{"path":[]},{"path":"https://github.com/paulnorthrop/lax/reference/lax-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"lax: Loglikelihood Adjustment for Extreme Value Models — lax-package","text":"Maintainer: Paul J. Northrop p.northrop@ucl.ac.uk [copyright holder] Authors: Camellia Yin [copyright holder]","code":""},{"path":"https://github.com/paulnorthrop/lax/reference/logLik.logLikVec.html","id":null,"dir":"Reference","previous_headings":"","what":"Sum loglikelihood contributions from individual observations — logLik.logLikVec","title":"Sum loglikelihood contributions from individual observations — logLik.logLikVec","text":"S3 logLik method logLikVec objects.","code":""},{"path":"https://github.com/paulnorthrop/lax/reference/logLik.logLikVec.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sum loglikelihood contributions from individual observations — logLik.logLikVec","text":"","code":"# S3 method for class 'logLikVec' logLik(object, ...)"},{"path":"https://github.com/paulnorthrop/lax/reference/logLik.logLikVec.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sum loglikelihood contributions from individual observations — logLik.logLikVec","text":"object object class \"logLikVec\" return logLikVec method. ... arguments.","code":""},{"path":"https://github.com/paulnorthrop/lax/reference/logLik.logLikVec.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sum loglikelihood contributions from individual observations — logLik.logLikVec","text":"object class \"logLik\". value   loglikelihood, attributes \"df\" (degrees freedom) giving   number free parameters, \"nobs\" giving number   observations.","code":""},{"path":"https://github.com/paulnorthrop/lax/reference/logLik.logLikVec.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Sum loglikelihood contributions from individual observations — logLik.logLikVec","text":"See alogLik: loglikelihood adjustment model fits.","code":""},{"path":"https://github.com/paulnorthrop/lax/reference/logLik.logLikVec.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sum loglikelihood contributions from individual observations — logLik.logLikVec","text":"See example bernoulli.","code":""},{"path":"https://github.com/paulnorthrop/lax/reference/logLikVec.html","id":null,"dir":"Reference","previous_headings":"","what":"Evaluate loglikelihood contributions from specific observations — logLikVec","title":"Evaluate loglikelihood contributions from specific observations — logLikVec","text":"Generic function calculating loglikelihood contributions individual observations fitted model.","code":""},{"path":"https://github.com/paulnorthrop/lax/reference/logLikVec.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluate loglikelihood contributions from specific observations — logLikVec","text":"","code":"logLikVec(object, ...)"},{"path":"https://github.com/paulnorthrop/lax/reference/logLikVec.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluate loglikelihood contributions from specific observations — logLikVec","text":"object fitted model object. ... arguments.","code":""},{"path":"https://github.com/paulnorthrop/lax/reference/logLikVec.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Evaluate loglikelihood contributions from specific observations — logLikVec","text":"object class \"logLikVec\", vector containing   individual loglikelihood contributions.","code":""},{"path":"https://github.com/paulnorthrop/lax/reference/logLikVec.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Evaluate loglikelihood contributions from specific observations — logLikVec","text":"See alogLik: loglikelihood adjustment model fits.","code":""},{"path":"https://github.com/paulnorthrop/lax/reference/logLikVec.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Evaluate loglikelihood contributions from specific observations — logLikVec","text":"See example bernoulli.","code":""},{"path":"https://github.com/paulnorthrop/lax/reference/mev.html","id":null,"dir":"Reference","previous_headings":"","what":"Loglikelihood adjustment for mev fits — mev","title":"Loglikelihood adjustment for mev fits — mev","text":"S3 alogLik method perform loglikelihood adjustment fitted extreme value model objects returned functions fit.gev, fit.gpd, fit.pp fit.rlarg mev package.","code":""},{"path":"https://github.com/paulnorthrop/lax/reference/mev.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Loglikelihood adjustment for mev fits — mev","text":"","code":"# S3 method for class 'mev_gev' alogLik(x, cluster = NULL, use_vcov = TRUE, ...)  # S3 method for class 'mev_pp' alogLik(x, cluster = NULL, use_vcov = TRUE, ...)  # S3 method for class 'mev_gpd' alogLik(x, cluster = NULL, use_vcov = TRUE, ...)  # S3 method for class 'mev_egp' alogLik(x, cluster = NULL, use_vcov = TRUE, ...)  # S3 method for class 'mev_rlarg' alogLik(x, cluster = NULL, use_vcov = TRUE, ...)"},{"path":"https://github.com/paulnorthrop/lax/reference/mev.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Loglikelihood adjustment for mev fits — mev","text":"x fitted model object certain associated S3 methods. See Details. cluster vector factor indicating cluster   respective log-likelihood contributions loglik originate.   length cluster must consistent estfun   method used estimation 'meat' V sandwich   estimator covariance matrix parameters passed   adjust_loglik.  cases, cluster   must length equal number observations data.    exception GP () model (binom = FALSE),   cluster may either contain value observation raw   data, threshold exceedance data. cluster supplied (NULL)   assumed observation forms cluster.   See Details details. use_vcov logical scalar.  use vcov S3 method x (exists) estimate Hessian independence loglikelihood passed argument H adjust_loglik? Otherwise, H estimated inside adjust_loglik using optimHess. ... arguments passed functions sandwich package meat (cluster = NULL), meatCL (cluster NULL).","code":""},{"path":"https://github.com/paulnorthrop/lax/reference/mev.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Loglikelihood adjustment for mev fits — mev","text":"object inheriting class \"chandwich\".  See   adjust_loglik.   class(x) vector length 5. first 3 components   c(\"lax\", \"chandwich\", \"mev\").   4th component depends model fitted.   \"gev\" fit.gev used;   \"gpd\" fit.gpd used;   \"pp\" fit.pp used;   \"egp\" fit.egp used;   \"rlarg\" fit.rlarg used;   5th component \"stat\" (stationary).","code":""},{"path":"https://github.com/paulnorthrop/lax/reference/mev.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Loglikelihood adjustment for mev fits — mev","text":"See alogLik details. x returned fit.pp data xdat supplied fit.pp must contain data, threshold exceedances non-exceedances.","code":""},{"path":"https://github.com/paulnorthrop/lax/reference/mev.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Loglikelihood adjustment for mev fits — mev","text":"Chandler, R. E. Bate, S. (2007). Inference clustered   data using independence loglikelihood. Biometrika,   94(1), 167-183. doi:10.1093/biomet/asm015 Suveges, M. Davison, . C. (2010) Model   misspecification peaks threshold analysis, Annals   Applied Statistics, 4(1), 203-221.   doi:10.1214/09-AOAS292 Zeileis (2006) Object-Oriented Computation Sandwich   Estimators.  Journal Statistical Software, 16, 1-16.   doi:10.18637/jss.v016.i09","code":""},{"path":[]},{"path":"https://github.com/paulnorthrop/lax/reference/mev.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Loglikelihood adjustment for mev fits — mev","text":"","code":"# We need the mev package got_mev <- requireNamespace(\"mev\", quietly = TRUE)  if (got_mev) {   library(mev)   # An example from the mev::gev.fit documentation   gev_mev <- fit.gev(revdbayes::portpirie)   adj_gev_mev <- alogLik(gev_mev)   summary(adj_gev_mev)    # Use simulated data   set.seed(1112019)   x <- revdbayes::rgp(365 * 10, loc = 0, scale = 1, shape = 0.1)   pfit <- fit.pp(x, threshold = 1, npp = 365)   adj_pfit <- alogLik(pfit)   summary(adj_pfit)    # An example from the mev::fit.gpd documentation   gpd_mev <- fit.gpd(eskrain, threshold = 35, method = 'Grimshaw')   adj_gpd_mev <- alogLik(gpd_mev)   summary(adj_gpd_mev)    # An example from the mev::fit.egp documentation   # (model = \"egp1\" and model = \"egp3\" also work)   xdat <- evd::rgpd(n = 100, loc = 0, scale = 1, shape = 0.5)   fitted <- fit.egp(xdat = xdat, thresh = 1, model = \"egp2\", show = FALSE)   adj_fitted <- alogLik(fitted)   summary(adj_fitted)    # An example from the mev::fit.rlarg documentation   set.seed(31102019)   xdat <- rrlarg(n = 10, loc = 0, scale = 1, shape = 0.1, r = 4)   fitr <- fit.rlarg(xdat)   adj_fitr <- alogLik(fitr)   summary(adj_fitr) } #>  #> Attaching package: 'mev' #> The following object is masked _by_ '.GlobalEnv': #>  #>     venice #> The following objects are masked from 'package:fExtremes': #>  #>     dgev, pgev, qgev, rgev #> The following objects are masked from 'package:evir': #>  #>     dgev, pgev, qgev, rgev #> The following objects are masked from 'package:eva': #>  #>     pgev, qgev #> The following object is masked from 'package:extRemes': #>  #>     taildep #> The following objects are masked from 'package:evd': #>  #>     dgev, pgev, qgev, rgev, venice #>           MLE     SE adj. SE #> loc   -0.1223 0.2859 0.29490 #> scale  1.0750 0.2450 0.20520 #> shape  0.2490 0.1552 0.07926"},{"path":"https://github.com/paulnorthrop/lax/reference/ow.html","id":null,"dir":"Reference","previous_headings":"","what":"Oxford and Worthing annual maximum temperatures — ow","title":"Oxford and Worthing annual maximum temperatures — ow","text":"Annual maximum temperatures Oxford Worthing (England), period 1901 1980.","code":""},{"path":"https://github.com/paulnorthrop/lax/reference/ow.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Oxford and Worthing annual maximum temperatures — ow","text":"","code":"ow"},{"path":"https://github.com/paulnorthrop/lax/reference/ow.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Oxford and Worthing annual maximum temperatures — ow","text":"dataframe 80 rows 4 columns. Column 1, temp: annual maximum temperatures degrees       Fahrenheit. Column 2, year: year maximum recorded. Column 3, name: name location, \"oxford\" \"worthing\" Column 4, loc: location: 1 \"oxford\", -1       \"worthing\"","code":""},{"path":"https://github.com/paulnorthrop/lax/reference/ow.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Oxford and Worthing annual maximum temperatures — ow","text":"Tabony, R. C. (1983) Extreme value analysis meteorology.  Meteorological Magazine, 112, 77-98.","code":""},{"path":"https://github.com/paulnorthrop/lax/reference/ow.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Oxford and Worthing annual maximum temperatures — ow","text":"Chandler, R. E. Bate, S. (2007). Inference clustered   data using independence loglikelihood. Biometrika,   94(1), 167-183. doi:10.1093/biomet/asm015","code":""},{"path":"https://github.com/paulnorthrop/lax/reference/plot.retlev.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot diagnostics for a retlev object — plot.retlev","title":"Plot diagnostics for a retlev object — plot.retlev","text":"plot method objects class c(\"retlev\", \"lax\").","code":""},{"path":"https://github.com/paulnorthrop/lax/reference/plot.retlev.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot diagnostics for a retlev object — plot.retlev","text":"","code":"# S3 method for class 'retlev' plot(x, y = NULL, level = NULL, legend = TRUE, digits = 3, plot = TRUE, ...)"},{"path":"https://github.com/paulnorthrop/lax/reference/plot.retlev.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot diagnostics for a retlev object — plot.retlev","text":"x object class c(\"retlev\", \"lax\"), result call return_level, using prof = TRUE. y used. level numeric scalar (0, 1).  confidence level required confidence interval m-year return level. level supplied x$level used. level must larger x$level. legend logical scalar.  add legend (top right plot) gives approximate values MLE 100level% confidence limits? digits integer. Passed signif round values legend. plot logical scalar.  TRUE plot produced. Otherwise, , MLE confidence limits returned. ... arguments passed plot.","code":""},{"path":"https://github.com/paulnorthrop/lax/reference/plot.retlev.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot diagnostics for a retlev object — plot.retlev","text":"numeric vector length 3 containing lower   100level% confidence limit, MLE upper   100level% confidence limit.","code":""},{"path":"https://github.com/paulnorthrop/lax/reference/plot.retlev.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot diagnostics for a retlev object — plot.retlev","text":"Plots profile loglikelihood return level, provided   x returned call return_level using   prof = TRUE.  Horizontal lines indicate values   maximised loglikelihood critical level used calculate   confidence limits.   level smaller x$level approximate   100level% confidence limits recalculated based   information contained x$for_plot.","code":""},{"path":"https://github.com/paulnorthrop/lax/reference/plot.retlev.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot diagnostics for a retlev object — plot.retlev","text":"See examples return_level.","code":""},{"path":[]},{"path":"https://github.com/paulnorthrop/lax/reference/POT.html","id":null,"dir":"Reference","previous_headings":"","what":"Loglikelihood adjustment for POT fits — POT","title":"Loglikelihood adjustment for POT fits — POT","text":"S3 alogLik method perform loglikelihood adjustment fitted extreme value model objects returned fitGPD function POT package. model must fitted using maximum likelihood estimation.","code":""},{"path":"https://github.com/paulnorthrop/lax/reference/POT.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Loglikelihood adjustment for POT fits — POT","text":"","code":"# S3 method for class 'uvpot' alogLik(x, cluster = NULL, use_vcov = TRUE, ...)"},{"path":"https://github.com/paulnorthrop/lax/reference/POT.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Loglikelihood adjustment for POT fits — POT","text":"x fitted model object certain associated S3 methods. See Details. cluster vector factor indicating cluster   respective log-likelihood contributions loglik originate.   length cluster must consistent estfun   method used estimation 'meat' V sandwich   estimator covariance matrix parameters passed   adjust_loglik.  cases, cluster   must length equal number observations data.    exception GP () model (binom = FALSE),   cluster may either contain value observation raw   data, threshold exceedance data. cluster supplied (NULL)   assumed observation forms cluster.   See Details details. use_vcov logical scalar.  use vcov S3 method x (exists) estimate Hessian independence loglikelihood passed argument H adjust_loglik? Otherwise, H estimated inside adjust_loglik using optimHess. ... arguments passed functions sandwich package meat (cluster = NULL), meatCL (cluster NULL).","code":""},{"path":"https://github.com/paulnorthrop/lax/reference/POT.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Loglikelihood adjustment for POT fits — POT","text":"object inheriting class \"chandwich\".  See   adjust_loglik. class(x) c(\"lax\", \"chandwich\", \"POT\", \"pot\", \"gpd\").","code":""},{"path":"https://github.com/paulnorthrop/lax/reference/POT.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Loglikelihood adjustment for POT fits — POT","text":"See alogLik details.","code":""},{"path":"https://github.com/paulnorthrop/lax/reference/POT.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Loglikelihood adjustment for POT fits — POT","text":"Chandler, R. E. Bate, S. (2007). Inference clustered   data using independence loglikelihood. Biometrika,   94(1), 167-183. doi:10.1093/biomet/asm015 Suveges, M. Davison, . C. (2010) Model   misspecification peaks threshold analysis, Annals   Applied Statistics, 4(1), 203-221.   doi:10.1214/09-AOAS292 Zeileis (2006) Object-Oriented Computation Sandwich   Estimators.  Journal Statistical Software, 16, 1-16.   doi:10.18637/jss.v016.i09","code":""},{"path":[]},{"path":"https://github.com/paulnorthrop/lax/reference/POT.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Loglikelihood adjustment for POT fits — POT","text":"","code":"# We need the POT package got_POT <- requireNamespace(\"POT\", quietly = TRUE) #> Registered S3 methods overwritten by 'POT': #>   method      from #>   print.bvpot evd  #>   plot.bvpot  evd   if (got_POT) {   library(POT)   # An example from the POT::fitgpd documentation.   set.seed(4082019)   x <- POT::rgpd(200, 1, 2, 0.25)   fit <- fitgpd(x, 1, \"mle\")   adj_fit <- alogLik(fit) } #>  #> Attaching package: 'POT' #> The following objects are masked from 'package:fExtremes': #>  #>     dgpd, pgpd, qgpd, rgpd #> The following objects are masked from 'package:evir': #>  #>     dgpd, pgpd, qgpd, rgpd #> The following objects are masked from 'package:eva': #>  #>     dgpd, pgpd, qgpd, rgpd #> The following object is masked from 'package:extRemes': #>  #>     mrlplot #> The following objects are masked from 'package:evd': #>  #>     dens, dgpd, exiplot, mrlplot, pgpd, pp, qgpd, qq, rgpd, tcplot"},{"path":"https://github.com/paulnorthrop/lax/reference/pot_refit.html","id":null,"dir":"Reference","previous_headings":"","what":"Fits a Poisson point process to the data, an approach sometimes known as peaks over thresholds (POT), and returns an object of class ","title":"Fits a Poisson point process to the data, an approach sometimes known as peaks over thresholds (POT), and returns an object of class ","text":"slightly modified versions pot function evir package. main modification add returned object argument data supplied user.  added returned (list) object name input_data.","code":""},{"path":"https://github.com/paulnorthrop/lax/reference/pot_refit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fits a Poisson point process to the data, an approach sometimes known as peaks over thresholds (POT), and returns an object of class ","text":"","code":"pot_refit(data, threshold = NA, nextremes = NA, run = NA, picture = TRUE, ...)"},{"path":"https://github.com/paulnorthrop/lax/reference/pot_refit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fits a Poisson point process to the data, an approach sometimes known as peaks over thresholds (POT), and returns an object of class ","text":"data numeric vector data, may times attribute containing (object class \"POSIXct\", object can converted class; see .POSIXct) times/dates observation. times attribute exists, data assumed equally spaced. threshold threshold value (either nextremes must given ). nextremes number upper extremes used (either threshold must given ). run data declustered run length parameter runs method (see decluster) entered . picture whether picture drawn declustering performed. ... arguments passed optim.","code":""},{"path":"https://github.com/paulnorthrop/lax/reference/pot_refit.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Fits a Poisson point process to the data, an approach sometimes known as peaks over thresholds (POT), and returns an object of class ","text":"Bernhard Pfaff Alexander McNeil (2018). evir: Extreme   Values R. R package version 1.7-4.   https://CRAN.R-project.org/package=evir.","code":""},{"path":"https://github.com/paulnorthrop/lax/reference/pot_refit.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fits a Poisson point process to the data, an approach sometimes known as peaks over thresholds (POT), and returns an object of class ","text":"","code":"# We need the evir package got_evir <- requireNamespace(\"evir\", quietly = TRUE) if (got_evir) {   library(evir)   data(danish)   out <- pot(danish, 10)   ls(out)   out <- pot_refit(danish, 10)   ls(out) } #>  [1] \"converged\"     \"data\"          \"input_data\"    \"intensity\"     #>  [5] \"n\"             \"n.exceed\"      \"nllh.final\"    \"p.less.thresh\" #>  [9] \"par.ests\"      \"par.ses\"       \"period\"        \"run\"           #> [13] \"span\"          \"threshold\"     \"varcov\""},{"path":"https://github.com/paulnorthrop/lax/reference/print.retlev.html","id":null,"dir":"Reference","previous_headings":"","what":"Print method for retlev object — print.retlev","title":"Print method for retlev object — print.retlev","text":"print method objects class c(\"retlev\", \"lax\").","code":""},{"path":"https://github.com/paulnorthrop/lax/reference/print.retlev.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print method for retlev object — print.retlev","text":"","code":"# S3 method for class 'retlev' print(x, digits = max(3L, getOption(\"digits\") - 3L), ...)"},{"path":"https://github.com/paulnorthrop/lax/reference/print.retlev.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print method for retlev object — print.retlev","text":"x object class c(\"retlev\", \"lax\"), result call return_level. digits argument digits print.default. ... Additional arguments.  None used function.","code":""},{"path":"https://github.com/paulnorthrop/lax/reference/print.retlev.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print method for retlev object — print.retlev","text":"argument x, invisibly,   print methods.","code":""},{"path":"https://github.com/paulnorthrop/lax/reference/print.retlev.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Print method for retlev object — print.retlev","text":"Prints call return_level estimates   100x$level% confidence limits x$m-year   return level.","code":""},{"path":"https://github.com/paulnorthrop/lax/reference/print.retlev.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Print method for retlev object — print.retlev","text":"See examples return_level.","code":""},{"path":[]},{"path":"https://github.com/paulnorthrop/lax/reference/print.summary.retlev.html","id":null,"dir":"Reference","previous_headings":"","what":"Print method for objects of class ","title":"Print method for objects of class ","text":"print method object x class \"summary.retlev\".","code":""},{"path":"https://github.com/paulnorthrop/lax/reference/print.summary.retlev.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print method for objects of class ","text":"","code":"# S3 method for class 'summary.retlev' print(x, ...)"},{"path":"https://github.com/paulnorthrop/lax/reference/print.summary.retlev.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print method for objects of class ","text":"x object class \"summary.retlev\", result call summary.retlev. ... Additional arguments passed print.default.","code":""},{"path":"https://github.com/paulnorthrop/lax/reference/print.summary.retlev.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print method for objects of class ","text":"argument x, invisibly,   print methods.","code":""},{"path":"https://github.com/paulnorthrop/lax/reference/print.summary.retlev.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Print method for objects of class ","text":"Prints call numeric matrix x$matrix returned   summary.retlev.","code":""},{"path":"https://github.com/paulnorthrop/lax/reference/print.summary.retlev.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Print method for objects of class ","text":"See examples return_level.","code":""},{"path":[]},{"path":"https://github.com/paulnorthrop/lax/reference/return_level.html","id":null,"dir":"Reference","previous_headings":"","what":"Return Level Inferences for Stationary Extreme Value Models — return_level","title":"Return Level Inferences for Stationary Extreme Value Models — return_level","text":"Calculates point estimates confidence intervals m-year return levels stationary extreme value fitted model objects returned alogLik.  Two types interval may returned: () intervals based approximate large-sample normality maximum likelihood estimator return level, symmetric point estimate, (b) profile likelihood-based intervals based (adjusted) loglikelihood.","code":""},{"path":"https://github.com/paulnorthrop/lax/reference/return_level.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Return Level Inferences for Stationary Extreme Value Models — return_level","text":"","code":"return_level(   x,   m = 100,   level = 0.95,   npy = 1,   prof = TRUE,   inc = NULL,   type = c(\"vertical\", \"cholesky\", \"spectral\", \"none\") )"},{"path":"https://github.com/paulnorthrop/lax/reference/return_level.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Return Level Inferences for Stationary Extreme Value Models — return_level","text":"x object inheriting class \"lax\" returned alogLik. m numeric scalar.  return period, years. level numeric scalar (0, 1).  confidence level required confidence interval m-year return level. npy numeric scalar.  (mean) number observations per year. Setting appropriately important. See Details. prof logical scalar.  calculate intervals based profile loglikelihood? inc numeric scalar. relevant prof = TRUE. increment return level move upwards downwards MLE return level search lower upper confidence limits.  supplied inc set one hundredth length symmetric confidence interval return level. type character scalar.  argument type function returned adjust_loglik, , type adjustment made independence loglikelihood function creating adjusted loglikelihood function.  See Details Value adjust_loglik.","code":""},{"path":"https://github.com/paulnorthrop/lax/reference/return_level.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Return Level Inferences for Stationary Extreme Value Models — return_level","text":"object (list) class \"retlev\", \"lax\"   components rl_sym,rl_prof Named numeric vectors containing respective     lower 100level% limit, MLE upper     100level% limit return level.     prof = FALSE rl_prof missing. rl_se Estimated standard error return level. max_loglik,crit,for_plot prof = TRUE     components present, containing respectively: maximised     loglikelihood; critical value matrix return levels     first column (ret_levs) corresponding values     (adjusted) profile loglikelihood (prof_loglik). m,level input values m level. call call return_level.","code":""},{"path":"https://github.com/paulnorthrop/lax/reference/return_level.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Return Level Inferences for Stationary Extreme Value Models — return_level","text":"present return_level supports GEV models. Care must taken specifying input value npy. GEV models: common one observation per year,      either data annual maxima year      maximum value particular season extracted raw      data. case, npy = 1, default.  instead      extract maximum values first second halves      year npy = 2. Binomial-GP models: npy provides information      (intended) frequency sampling time, , number      observations observed year      missing values.  number observations may vary years      npy set equal mean number observations      per year. Supplying npy binomial-GP models.   value npy (equivalent, perhaps differently named,   quantity) may set call fit GP model.   example, gpd.fit() function ismev package   npy argument value npy stored   fitted model object.  npy supplied user call   return_level used preference value   stored fitted model object.  two values differ   warning given. details definition estimation return levels see   Inference return levels vignette. profile likelihood-based intervals calculated   reparameterising terms m-year return level estimating   values (adjusted) profile loglikelihood reaches   critical value logLik(x) - 0.5 * stats::qchisq(level, 1).   achieved calculating profile loglikelihood sequence   values return level governed inc. profile   loglikelihood drops critical value lower upper limits   estimated interpolating linearly cases lying either side   critical value. smaller inc accurate (slower)   calculation .","code":""},{"path":"https://github.com/paulnorthrop/lax/reference/return_level.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Return Level Inferences for Stationary Extreme Value Models — return_level","text":"Coles, S. G. (2001) Introduction Statistical   Modeling Extreme Values, Springer-Verlag, London.   doi:10.1007/978-1-4471-3675-0_3","code":""},{"path":[]},{"path":"https://github.com/paulnorthrop/lax/reference/return_level.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Return Level Inferences for Stationary Extreme Value Models — return_level","text":"","code":"# GEV model -----  got_evd <- requireNamespace(\"evd\", quietly = TRUE)  if (got_evd) {   library(evd)   # An example from the evd::fgev documentation   set.seed(4082019)   uvdata <- evd::rgev(100, loc = 0.13, scale = 1.1, shape = 0.2)   M1 <- fgev(uvdata)   adj_fgev <- alogLik(M1)   # Large inc set here for speed, sacrificing accuracy   rl <- return_level(adj_fgev, inc = 0.5)   summary(rl)   rl   plot(rl) }  #>     lower       mle     upper  #>  5.337685  6.992529 10.354765   got_ismev <- requireNamespace(\"ismev\", quietly = TRUE)  if (got_ismev) {   library(ismev)   # An example from the ismev::gev.fit documentation   gev_fit <- gev.fit(revdbayes::portpirie, show = FALSE)   adj_gev_fit <- alogLik(gev_fit)   # Large inc set here for speed, sacrificing accuracy   rl <- return_level(adj_gev_fit, inc = 0.05)   summary(rl)   rl   plot(rl) }  #>    lower      mle    upper  #> 4.518708 4.688429 5.070614   # Binomial-GP model -----  if (got_ismev) {   library(ismev)   data(rain)   # An example from the ismev::gpd.fit documentation   rain_fit <- gpd.fit(rain, 10, show = FALSE)   adj_rain_fit <- alogLik(rain_fit, binom = TRUE)   # Large inc set here for speed, sacrificing accuracy   rl <- return_level(adj_rain_fit, inc = 2.5)   summary(rl)   rl   plot(rl) }  #>     lower       mle     upper  #>  76.00807  87.01603 103.60984   if (got_ismev) {   # Use Newlyn seas surges data from the exdex package   surges <- exdex::newlyn   u <- quantile(surges, probs = 0.9)   newlyn_fit <- gpd.fit(surges, u, show = FALSE)   # Create 5 clusters each corresponding approximately to 1 year of data   cluster <- rep(1:5, each = 579)[-1]   adj_newlyn_fit <- alogLik(newlyn_fit, cluster = cluster, binom = TRUE,                             cadjust = FALSE)   rl <- return_level(adj_newlyn_fit, inc = 0.02)   rl    # Add inference about the extremal index theta, using K = 1   adj_newlyn_theta <- alogLik(newlyn_fit, cluster = cluster, binom = TRUE,                               k = 1, cadjust = FALSE)   rl <- return_level(adj_newlyn_theta, inc = 0.02)   rl } #>  #> Call: #> return_level(x = adj_newlyn_theta, inc = 0.02) #>  #> MLE and 95% confidence limits for the 100-year return level #>  #> Normal interval: #>  lower     mle   upper   #> 0.7489  0.8424  0.9359   #>  #>  Profile likelihood-based interval: #>  lower     mle   upper   #> 0.7593  0.8424  0.9450"},{"path":"https://github.com/paulnorthrop/lax/reference/summary.retlev.html","id":null,"dir":"Reference","previous_headings":"","what":"Summary method for a ","title":"Summary method for a ","text":"summary method objects class c(\"retlev\", \"lax\").","code":""},{"path":"https://github.com/paulnorthrop/lax/reference/summary.retlev.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summary method for a ","text":"","code":"# S3 method for class 'retlev' summary(object, digits, ...)"},{"path":"https://github.com/paulnorthrop/lax/reference/summary.retlev.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summary method for a ","text":"object object class c(\"retlev\", \"lax\"), result call return_level. digits integer. Used number formatting signif.  digits specified (.e. missing) signif() called (.e. rounding performed). ... Additional arguments.  None used function.","code":""},{"path":"https://github.com/paulnorthrop/lax/reference/summary.retlev.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summary method for a ","text":"Returns list containing list element object$call   numeric matrix matrix containing MLE estimated   SE return level.","code":""},{"path":"https://github.com/paulnorthrop/lax/reference/summary.retlev.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summary method for a ","text":"See examples return_level.","code":""},{"path":[]},{"path":"https://github.com/paulnorthrop/lax/reference/texmex.html","id":null,"dir":"Reference","previous_headings":"","what":"Loglikelihood adjustment of texmex fits — texmex","title":"Loglikelihood adjustment of texmex fits — texmex","text":"S3 alogLik method perform loglikelihood adjustment fitted extreme value model objects returned evm function texmex package. model must fitted using maximum likelihood estimation.","code":""},{"path":"https://github.com/paulnorthrop/lax/reference/texmex.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Loglikelihood adjustment of texmex fits — texmex","text":"","code":"# S3 method for class 'evmOpt' alogLik(x, cluster = NULL, use_vcov = TRUE, ...)"},{"path":"https://github.com/paulnorthrop/lax/reference/texmex.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Loglikelihood adjustment of texmex fits — texmex","text":"x fitted model object certain associated S3 methods. See Details. cluster vector factor indicating cluster   respective log-likelihood contributions loglik originate.   length cluster must consistent estfun   method used estimation 'meat' V sandwich   estimator covariance matrix parameters passed   adjust_loglik.  cases, cluster   must length equal number observations data.    exception GP () model (binom = FALSE),   cluster may either contain value observation raw   data, threshold exceedance data. cluster supplied (NULL)   assumed observation forms cluster.   See Details details. use_vcov logical scalar.  use vcov S3 method x (exists) estimate Hessian independence loglikelihood passed argument H adjust_loglik? Otherwise, H estimated inside adjust_loglik using optimHess. ... arguments passed functions sandwich package meat (cluster = NULL), meatCL (cluster NULL).","code":""},{"path":"https://github.com/paulnorthrop/lax/reference/texmex.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Loglikelihood adjustment of texmex fits — texmex","text":"object inheriting class \"chandwich\".  See   adjust_loglik.   class(x) vector length 5. first 3 components   c(\"lax\", \"chandwich\", \"texmex\").   remaining 2 components depend model fitted.   4th component : \"gev\" x$family$name = \"GEV\";   \"gpd\" x$family$name = \"GPD\";   \"egp3\" x$family$name = \"EGP3\".   5th component   \"stat\" covariates mode   \"nonstat\" otherwise.","code":""},{"path":"https://github.com/paulnorthrop/lax/reference/texmex.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Loglikelihood adjustment of texmex fits — texmex","text":"See alogLik details.","code":""},{"path":"https://github.com/paulnorthrop/lax/reference/texmex.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Loglikelihood adjustment of texmex fits — texmex","text":"Chandler, R. E. Bate, S. (2007). Inference clustered   data using independence loglikelihood. Biometrika,   94(1), 167-183. doi:10.1093/biomet/asm015 Suveges, M. Davison, . C. (2010) Model   misspecification peaks threshold analysis, Annals   Applied Statistics, 4(1), 203-221.   doi:10.1214/09-AOAS292 Zeileis (2006) Object-Oriented Computation Sandwich   Estimators.  Journal Statistical Software, 16, 1-16.   doi:10.18637/jss.v016.i09","code":""},{"path":[]},{"path":"https://github.com/paulnorthrop/lax/reference/texmex.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Loglikelihood adjustment of texmex fits — texmex","text":"","code":"if (FALSE) { # \\dontrun{ # Not run to avoid a CRAN check error inherited from the texmex package # We need the texmex package, and ismev for the fremantle dataset got_texmex <- requireNamespace(\"texmex\", quietly = TRUE) got_ismev <- requireNamespace(\"ismev\", quietly = TRUE) if (got_texmex) {   library(texmex)   # Examples from the texmex::evm documentation    # GEV   mod <- evm(SeaLevel, data = texmex::portpirie, family = gev)   adj_mod <- alogLik(mod)   summary(adj_mod)    # GP   mod <- evm(rain, th = 30)   adj_mod <- alogLik(mod)   summary(adj_mod)   mod <- evm(rain, th = 30, cov = \"sandwich\")   mod$se   vcov(adj_mod)   vcov(mod)    # EGP3   mod <- evm(rain, th = 30, family = egp3)   adj_mod <- alogLik(mod)   summary(adj_mod)    # GP regression   # An example from page 119 of Coles (2001)   n_rain <- length(rain)   rain_df <- data.frame(rain = rain, time = 1:n_rain / n_rain)   evm_fit <- evm(y = rain, data = rain_df, family = gpd, th = 30,                  phi = ~ time)   adj_evm_fit <- alogLik(evm_fit)   summary(adj_evm_fit)   evm_fit <- evm(y = rain, data = rain_df, family = gpd, th = 30,                  phi = ~ time, cov = \"sandwich\")   evm_fit$se   vcov(adj_evm_fit)   vcov(evm_fit)    # GEV regression   # An example from page 113 of Coles (2001)   if (got_ismev) {     library(ismev)     data(fremantle)     new_fremantle <- fremantle     # Set year 1897 to 1 for consistency with page 113 of Coles (2001)     new_fremantle[, \"Year\"] <- new_fremantle[, \"Year\"] - 1896     evm_fit <- evm(y = SeaLevel, data = new_fremantle, family = gev,                    mu = ~ Year + SOI)     adj_evm_fit <- alogLik(evm_fit)     summary(adj_evm_fit)   }    # An example from Chandler and Bate (2007)   # Note: evm uses phi = log(sigma)   evm_fit <- evm(temp, ow, gev, mu = ~ loc, phi = ~ loc, xi = ~loc)   adj_evm_fit <- alogLik(evm_fit, cluster = ow$year, cadjust = FALSE)   summary(adj_evm_fit) } } # }"},{"path":[]},{"path":"https://github.com/paulnorthrop/lax/news/index.html","id":"bug-fixes-1-2-4","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"lax 1.2.4","text":"Updates methods mev::fit.egp() comply versions 2.0 add new models. Add Details, Value Examples sections logLik.logLikVec.Rd logLikVec.Rd avoid CRAN HTML validation NOTE r-devel Debian.","code":""},{"path":"https://github.com/paulnorthrop/lax/news/index.html","id":"lax-123","dir":"Changelog","previous_headings":"","what":"lax 1.2.3","title":"lax 1.2.3","text":"CRAN release: 2024-02-25","code":""},{"path":"https://github.com/paulnorthrop/lax/news/index.html","id":"bug-fixes-1-2-3","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"lax 1.2.3","text":"Calls texmex::evm(), resulted CRAN package check ERRORs platforms, avoided.","code":""},{"path":"https://github.com/paulnorthrop/lax/news/index.html","id":"lax-122","dir":"Changelog","previous_headings":"","what":"lax 1.2.2","title":"lax 1.2.2","text":"CRAN release: 2023-12-02","code":""},{"path":"https://github.com/paulnorthrop/lax/news/index.html","id":"bug-fixes-1-2-2","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"lax 1.2.2","text":"Fixed issues incorrect use Rd files.","code":""},{"path":"https://github.com/paulnorthrop/lax/news/index.html","id":"lax-121","dir":"Changelog","previous_headings":"","what":"lax 1.2.1","title":"lax 1.2.1","text":"CRAN release: 2023-09-02","code":""},{"path":"https://github.com/paulnorthrop/lax/news/index.html","id":"bug-fixes-and-minor-improvements-1-2-1","dir":"Changelog","previous_headings":"","what":"Bug fixes and minor improvements","title":"lax 1.2.1","text":"original model object x added attribute \"original_fit\" object returned alogLik(x). documentation return_level() role npy explained accurate calculation used estimation return levels case npy equal 1. argument cluster supplied alogLik() method now returned attribute cluster returned object, rather default returned chandwich::adjust_loglik(). Create help file package correctly, alias lax-package. README.md: Used app.codecov.io base codecov link. Activated 3rd edition testthat package","code":""},{"path":"https://github.com/paulnorthrop/lax/news/index.html","id":"lax-120","dir":"Changelog","previous_headings":"","what":"lax 1.2.0","title":"lax 1.2.0","text":"CRAN release: 2021-07-20","code":""},{"path":"https://github.com/paulnorthrop/lax/news/index.html","id":"new-features-1-2-0","dir":"Changelog","previous_headings":"","what":"New features","title":"lax 1.2.0","text":"eva package now supported: functions gpdFit gevrFit.","code":""},{"path":"https://github.com/paulnorthrop/lax/news/index.html","id":"bug-fixes-and-minor-improvements-1-2-0","dir":"Changelog","previous_headings":"","what":"Bug fixes and minor improvements","title":"lax 1.2.0","text":"links end Details section main lax package help page corrected. Depreciated function testthat::context longer used. obsolete code deleted lax help file mev.","code":""},{"path":"https://github.com/paulnorthrop/lax/news/index.html","id":"lax-110","dir":"Changelog","previous_headings":"","what":"lax 1.1.0","title":"lax 1.1.0","text":"CRAN release: 2019-12-05","code":""},{"path":"https://github.com/paulnorthrop/lax/news/index.html","id":"new-features-1-1-0","dir":"Changelog","previous_headings":"","what":"New features","title":"lax 1.1.0","text":"mev package now supported: functions fit.gev, fit.gpd, fit.egp, fit.pp fit.rlarg. function rlarg.fit ismev package now supported.","code":""},{"path":"https://github.com/paulnorthrop/lax/news/index.html","id":"bug-fixes-and-minor-improvements-1-1-0","dir":"Changelog","previous_headings":"","what":"Bug fixes and minor improvements","title":"lax 1.1.0","text":"Unnecessary generic information concerning availability S3 methods removed Details sections package-specific loglikelihood adjustment documentation. tests internal function box_cox_deriv.","code":""}]
